[{"content":"begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。使用start transation with consistent snapshot 这个命令可以马上启动一个事务。\n在MySQL中有两个视图的概念：\n一个是view。它是一个用于查询语句定义的虚拟表，它的语法是：create view ...。\n另一个是InnoDB 在实现MVCC时用到的一致性读视图，即 consistent read view，用于支持RC（Read Commit 读提交）和RR（Repeatable 可重复读）隔离级别实现的。\n“快照”在 MVCC 里是怎么工作的？ 在可重复读隔离级别下，事务在启动的时候就“拍个快照”，这个快照时基于整库的。\n如果库有100G，那么启动一个事务就需要拷贝100G数据，这样实现是不现实的。\n快照是怎么实现的？ InnoDB 里面每个事务都有一个唯一的事务ID，叫做transaction id，它是在事务开始的时候向InnoDB 的事务系统申请的，是按照顺序严格递增的。\n而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。\n如图下所示，就是一个记录被多个事务连续更新后的状态。 图中的三个虚线箭头，就是undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。\n事务启动的时候，以启动的时刻为准，如果一个数据版本低于在事务启动之前生成的，那就可见，如果在启动之后才生成的，那就不可见。\n在实现上，InnoDB为每个事务构造了一个数据，用来保存这个事务的启动瞬间，当前正在“活跃”的所有事务ID，“活跃”指的是，启动了但还没提交。\n数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。\n这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。\n这样，对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：\n如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；\n如果落在黄色部分，那就包括两种情况 a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。\n** InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。**\n更新逻辑 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。\n当前读，读取的是最新版本，并且需要先获取对应记录的锁，如以下这些 SQL 类型：\n1 2 3 4 5 select ... lock in share mode select ... for update update 、delete 、insert 例如，要 update 一条记录，在事务执行过程中，如果不加锁，那么另一个事务可以 delete 这条数据并且能成功 commit ，就会产生冲突了。所以 update 的时候肯定要是当前读，得到最新的信息并且锁定相应的记录。\n事务的可重复读的能力是怎么实现的？ 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；\n在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。\n","date":"2022-06-12T00:00:00Z","permalink":"http://localhost:1313/p/%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84/","title":"事务到底是隔离的还是不隔离的？"},{"content":"从两阶段锁说起 实际上事务B的update语句会被阻塞，直至事务A执行commit之后，事务B才能继续执行。\n在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是等到事务结束才释放，这就是两阶段锁协议。\n如果你的事务中需要锁多个行，要把最可能造成冲突、最可能影响并发的锁尽量往后放。\n死锁和死锁检测 当并发系统出现资源循环依赖，就会导致这几个线程处于无限等待状态，称为死锁。\n两种解决死锁的策略：\n一种策略是直接进入等待，直至超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。\n另外一种策略是发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。\n使用show variables like 'innodb_deadlock_detect';可以查看系统参数。\n问题 如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：\n第一种，直接执行 delete from T limit 10000;\n第二种，在一个连接中循环执行 20 次 delete from T limit 500;\n第三种，在 20 个连接中同时执行 delete from T limit 500。\n一般会选择第二种。\n第一种方式单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。\n第三种方式会人为造成锁冲突。\n","date":"2022-06-12T00:00:00Z","permalink":"http://localhost:1313/p/%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E8%A1%8C%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D/","title":"行锁功过：怎么减少行锁对性能的影响？"},{"content":"覆盖索引 如果执行语句如:select ID from T where k between 3 and 5，这是只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表，这种情况我们称为覆盖索引。\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n最左前缀原则 可以看到，索引是按照索引定义里面出现的字段排序的。\n只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n在建立联合索引的时候，如何安排索引内的字段顺序? 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n索引下推 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n例如以下查询语句：\n1 mysql\u0026gt; select * from tuser where name like \u0026#39;张 %\u0026#39; and age=10 and ismale=1; 无索引下推\r有索引下推\r可以明显的看出，有索引下推的情况下减少了回表的次数。\n","date":"2022-06-08T00:00:00Z","permalink":"http://localhost:1313/p/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8B/","title":"深入浅出索引（下）"},{"content":"索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。\n索引常见模型 哈希表 哈希表是一种以键值对存储的数据结构，只要输入key，就可以根据key找到对应的vaule。不可避免的是会存在hash冲突，处理这种情况方法是拉出一个链表。（类比Java中HashMap结构）。\n优点：\n查找速度快，新增速度也快。 缺点：\n因为不是有序的，如果需要范围查询，速度是很慢的。 哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。\n有序数组 有序数组查询时，可以使用二分法进行搜索，时间复杂度是O(log(N))，并且有序数据还支持范围查询。但是需要插入的时候，就需要进行数据挪动（因为要保证顺序），成本是非常高的。\n因此，有序数组索引只适用于静态存储引擎。\n搜索树 二叉树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -\u0026gt; UserC -\u0026gt; UserF -\u0026gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。\n当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。\n二叉树的主要缺点是：当数据量很大的时候，树高会非常高，假如树高为20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。\nInnoDB 的索引模型 在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用的是B+树索引模型，所以数据都是存储在B+树中的。\n每一个索引在InnoDB中对应一颗B+树。\n从上图来看，索引类型分为：主键索引和非主键索引。\n主键索引在InnoDB中也成为聚簇索引（clustered index），非主键索引在InnoDB中成为二级索引（secondary index）。\n基于主键索引和非主键索引搜索的区别： 基于主键索引查询只需要搜索对应的这颗B+树。\n基于非主键索引首先先查到对应值的ID（假设ID为主键），再到ID索引树中搜索一次，这个过程称为回表。\n索引的维护 页分裂 B+ 树为了维护索引的有序性，在插入新值的时候需要做必要的维护，如果插入的数据需要在页的中间，那么就需要进行数据的挪动，空出位置，如果插入的页刚好满了，就会触发页分裂，页分裂除了会影响性能，而且会使整体空间利用率降低50%（因为之前一个页，分裂成了两个）。\n当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。\n基于业务字段做主键，往往不能保证插入的有序性，更容易造成页分裂，基于自增ID做主键，每插入一条记录都是追加操作，一般不会触发叶子结点分裂。由于每个非主键索引叶子结点都是主键的值，如果用整型做主键，只需要4个字节，如果是长整型，则是8个字节。\n显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。\n","date":"2022-06-07T00:00:00Z","permalink":"http://localhost:1313/p/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8A/","title":"深入浅出索引（上）"},{"content":"ACID (Atomicity、Consistency、Isolation、Durability)即原子性、一致性、隔离性、持久性。\n当数据库上有多个事务同时执行的时候，就可能会出现脏读（dirty read）、不可重复读（nonrepeatable read）、幻读（phantom read）的问题。\n隔离级别 SQL标准的隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复度（repeatable read）和串行化（serializable）。\n读未提交：一个事务还没有提交时，它做的变更就能被别的事务看到。\n读提交：一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读：一个事务执行过程中看到的数据，总是跟这个事务启动的时候看到的数据一致。当然在可重复读的隔离级别下，未提交的变更对其他事务也是不可见的。\n串行化：对同一条记录“写”会加“写锁”，“读”会加“读锁”。当出现读写冲突的时候，后访问的事务必须等待前一个事务执行完成，才能继续执行。\n事务隔离的实现 数据库隔离的实现上会创建一个视图，访问的时候以视图的逻辑结果为准。\n“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都会用这个视图。\n“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。\n**“读未提交”**隔离级别下直接返回记录上的最新值，没有视图的概念。\n“串行化”的隔离级别下直接使用加锁的方式避免并行访问。\n在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。\n同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。\n回滚日志系统会判断，当系统中没有比这个回滚日志更早的read-view的时候，日志会被删除。\n建议不要使用长事务 长事务意味着系统里面会存在很老的事务视图，由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n长事务还会占用锁资源，也可能拖垮整个库。\n通过以下语句可以查询持续时间超过60s的事务。\n1 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60 事务的启动方式 显式启动，begin或start transaction。配套的提交语句是commit，回滚语句是commit。\nset autocommit=0，这个命令会将这个线程自动提交关闭。意味着如果你只执行select语句，这个事务就启动了，而且不会自动提交。这个事务持续存在直到你主动执行commit或rollback语句，或者断开连接。\n建议使用set autocommit=1，通过显式语句的方式启动事务。\n在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n","date":"2022-06-07T00:00:00Z","permalink":"http://localhost:1313/p/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81/","title":"事务隔离：为什么你改了我还看不见？"},{"content":"redo log（重做日志） InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。\nbinlog（归档日志） binlog没有crash-safe能力，只能用于归档。\n这两种日志的不同点：\nredo log是InnoDB引擎特有的，binlog是MySQL的server层实现的，所有引擎都可以使用。\nredo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑。\nredo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n两阶段提交 1 mysql\u0026gt; update T set c=c+1 where ID=2; 执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程:\n执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。\n流程图如下所示： 如何让数据库恢复到半个月任意一秒？ 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库； 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。 总结 建议innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不丢失。\n建议sync_binlog 这个参数设置成 1 ，表示每次事务的 binlog 都持久化到磁盘，这样可以保证 MySQL 异常重启之后 binlog 不丢失。\n","date":"2022-06-06T00:00:00Z","permalink":"http://localhost:1313/p/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/","title":"日志系统：一条SQL更新语句是如何执行的?"},{"content":"一条SQL语句是如何执行的? 1 mysql\u0026gt; select * from T where ID=10； MySQL 分为Server层和存储引擎两部分。\nServer 层包括连接器、查询缓存、分析器、优化器、执行器等。涵盖MySQL的大多数核心服务功能，以及所有内置函数（如日期、时间、数字和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n存储引擎是插件式的，支持InnoDB、MyISAM、Memory等。从MySQL5.5.5版本以后默认存储引擎为InnoDB。\n连接器 连接器主要负责客户端和MySQL服务端进行连接的。可以通过show processlist查看连接信息，客户端和服务端默认连接超时为8小时，可以通过过wait_timeout参数配置。\n长连接使用一段时间后会导致MySQL内存长得很快，主要是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面。这些资源会在连接重新断开的时候才释放。 解决方案如下:\n定期断开长连接，使用一段时间，或者程序里面判断执行过一个占用内存大的查询后，断开连接，之后要查询再重连。\nMySQL5.7以后，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n查询缓存 之前执行的查询结果可能会以key-value对的形式缓存在内存中，如果查询能够直接在缓存中找到key，那么会直接把value返回给客户端。\n*** 大多数情况下不建议使用查询缓存。***\n如果表中的数据修改的比较频繁，查询缓存的命中率就会非常的低。MySQL提供了以下方式使用查询缓存：\n1 mysql\u0026gt; select SQL_CACHE * from T where ID=10； 注意： MySQL8.0版本直接将查询缓存的整块功能删掉了。\n分析器 分析器主要是分析语法是否正确，如果不正确就会收到“You have an error in your SQL syntax”的错误提醒,一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。如果查询语句中包含表中不存在的字段，也是在这一步分析。\n优化器 优化器的作用主要是决定使用那个索引，或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执行器 开始执行的时候，要先判断你对这个表有没有执行的查询权限，如果没有，就会返回没有权限的错误。使用慢SQL查询日志中看到rows_examined字段，表示执行过程中扫描了多少行，但有些情况下执行器调用一次，在引擎内部则扫描多行，因此引擎扫描行数跟rows_examined并不是完全相同。\n","date":"2022-06-05T00:00:00Z","permalink":"http://localhost:1313/p/%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/","title":"基础架构：一条SQL语句是如何执行的?"},{"content":"数据复制方案，人们通常希望达到以下几个目的：\n使数据在地理位置上更接近用户，从而降低访问延迟。 当部分组件出现故障，系统依然可以继续工作，从而提升可用性。 扩展至多台机器以同时提供数据访问服务，从而提高吞吐量。 三种比较流行的复制数据变化的方法：\n主从复制 多主节点复制 无主节点复制 复制技术存在很多折中的方案，例如：同步复制和异步复制，一般情况数据库会采用配置的形式来处理这些策略。\n主节点与从节点 主从复制的工作原理如下：\n指定一个副本为主节点，当客户写数据库时，只能通过主节点进行写入。 其他副本作为从副本，主副本将数据写入本地存储后，将数据更改作为复制日志或更改流发送到从副本。每个副本获取到更改数据后将其应用到本地，并且严格保持与主副本相同的写入顺序。 客户端读取数据时从主副本或者从副本进行读取，从客户端的角度看，从副本都是只读的。 同步复制与异步复制 同步复制是需要等从节点确认完成了写入之后，才会向用户报告完成。并将最新的写入对其他客户端可见。异步复制是主节点发送完消息之后立即返回，不需要等待从节点完成确认。\n同步复制的优点 一旦向用户确认，从节点可以明确保证完成了与主节点的更新同步，数据已处于最新版本。万一主节点发生故障，总是可以在从节点继续访问最新数据。\n同步复制的缺点 如果同步的从节点无法完成确认（例如由于从节点发送崩溃、网络故障或其他原因），写入就不能视为成功。主节点会阻塞其后面所有的写操作，直到同步副本确认完成。\n把所有从节点都设置为同步复制有些不切实际，实践中，可以将某一个节点设置为同步复制，其他节点设置为异步复制。万一同步复制的节点变得不可用或者性能下降，则将另外一个节点从异步模式提升为同步模式，这样可以保证至少有两个节点拥有最新的数据副本。这种配置有时称为半同步。\n异步复制的优点 不管从节点的数据多么滞后，主节点总是可以继续响应客户端的写请求，系统的吞吐性能更好。\n异步复制的缺点 如果主节点发生故障并且不可恢复，则所有尚未复制到从节点的数据将会丢失，这就意味着向客户端确认了写请求，但是却无法保证数据的持久化。\n配置新的从节点 如何考虑添加新的从节点，怎么保证主从数据一致性呢？\n在某个时间节点对主节点的数据副本生成一个一致性快照。 将快照拷贝到新的从节点。 从节点连接到主节点并请求快照点之后所发生的数据更改日志。因为在第一步创建快照时，快照与系统复制日志的某个确定的位置相关联。 获得日志之后，从节点应用这些快照点之后的所有数据变更，这个过程称之为追赶。接下来，他可以继续处理主节点上的新的数据变化。并重复1~4步骤。 从节点失效：追赶式恢复 从节点如果发生了崩溃或者网络闪断，则根据最后一笔事务的处理日志，从主节点拉取之后的所有数据的变更，收到所有数据的变更后，将其应用到本地用于追赶主节点，之后就和正常情况一样持续接收来自主节点数据流的变化。\n主节点失效：节点切换 确定主节点失效。大部分系统都采用了基于超时的机制判断节点是否失效，节点间频繁地互相发送心跳存活信息，如果某一个节点在一段时间内（例如30s）没有响应，则认为该节点发生了实效。 选举新的主节点。可以通过选举的方式来选举主节点，候选节点最好与主节点的数据差异最小，这样可以最小化数据丢失的风险。 重新配置系统使新的主节点生效。如果原主节点重新上线后，可能仍然认为自己是主节点，这是系统要确保原主节点降级为从节点，并认可新的主节点。 以上切换过程可能会发生很多变数 如果使用了异步复制，且失效之前，新的主节点并未收到原主节点的所有数据；在选举之后，原主节点很快又重新上线加入到集群，这是可能原主节点并未意识到角色的变化，还会尝试同步其他从节点，但其中的一个现在已经接管成为现任主节点。常见的解决方案是：原主节点上未完成复制的写请求就此丢弃，但这可能会违背数据更新持久化的承诺。\n如果数据库依赖于外部系统（例如Redis）一起协同使用，丢弃数据的方案就特别危险。例如，在GithHub的一次事故中，某个数据并完全的MySQL从节点提升为主节点，数据库使用了基于自增计数器将主键分配给新创建的行，但是因为新的主节点计数器落后于原主节点（即二者并非完全同步），它重新使用了已被原主节点分配出去的某些主键，而恰好这些主键已被外部Redis所引用，结果出现MySQL和Redis之间的不一致，最后导致了某些私有数据被错误的泄露给了其它用户。\n某些情况下，可能会发生两个节点同时认为自己是主节点，这种情况下被称为脑裂，它非常危险：两个主节点都可能接收写请求，并且没有很好解决冲突的办法，最后数据可能会丢失或者破坏，一种安全应急方案会强制关闭其中的一个节点。\n如何设置合适的超时来检查主节点失效？主节点失效后，超时时间设置的越长，也就意味着数据恢复的时间越长。如果设置的太短，可能会导致很多不必要的节点切换。例如：突然的负载峰值会导致节点的响应时间变长甚至超时，或者由于网络故障导致延迟增加。如果系统本身已经处于高负载或网络严重拥塞的情况下，不必要的切换只会导致系统的情况变得更糟。\n复制日志的实现 基于语句的复制 一些不适用的场景：\n任何调用非确定性的语句，如NOW()获取当前时间，或RAND()获取一个随机数等，可能会在不同副本产生不同的值。\n如果语句中使用自增列，或者依赖数据库的现有数据（例如：UPDATE \u0026hellip; WHERE \u0026hellip; \u0026lt;某些条件\u0026gt;），则所有副本必须按照相同的顺序执行，否则可能会带来不同的结果。\n有副作用的语句（例如：触发器、存储过程、用户自定义的函数等），可能会在每个副本产生不同的副作用。\n可能解决的方案是将不确定的函数替换成确定的结果，不过这种方式仍有许多地方需要考虑。\n基于预写日志（WAL）传输 对于日志结构的存储引擎（例如：SSTables和LSM-trees），日志是主要的存储方式。日志段在后台压缩并支持垃圾回收。\n对于采用覆盖写磁盘的Btree结构，每次修改会预先写入日志，如果系统崩溃，通过索引更新的方式迅速恢复到此前一直状态。\n缺点：\nWAL包含了哪些磁盘块的哪些字节发生了改变，诸如此类细节，这使得复制方案和存储引擎紧密耦合。如果数据库的存储格式从一个版本改为另一个版本，那么系统通常无法支持主从节点上运行不同版本的软件。\n基于行的逻辑日志复制 关系数据库的逻辑日志通常是指一些列记录数据行级别的写请求：\n对行的插入，日志包含所有相关列的新值。\n对于行的删除，日志有足够的的信息来唯一标识已删除的行。\n对于行的更新，日志包含足够的信息来唯一标识更新的行，以及所有列的新值。\nMySQL的二进制日志binlog（当配置基于行的复制时）使用该方式。\n基于触发器的复制 基于触发器复制支持更高的灵活性。例如将一种数据库的数据复制到另外一种数据库。触发器支持注册自己的应用层代码，使数据库发生数据更改时自动执行自定义代码。 基于触发器的复制通常比其他方式复制开销更高，也比数据库内置复制更容易出错或者暴露一些限制。\n复制滞后的问题 由于并非所有写入都反映到副本上，如果同时对主节点和从节点发起相同的查询，可能会得到不同的接口，这种不一致的状态只是暂时的，可能经过一段时间后，从节点最终会赶上主节点并与主节点保持一致。这种效应也被称为最终一致性。\n读自己的写 读自己的写也被称为读写一致性。实现读写一致性有多重可行方案：\n总是从主节点读取当前用户自己的数据，而从从节点读取其他用户的数据。\n跟踪数据最近更新时间，如果数据更新后一分钟内总是从主节点读取数据，并监控从节点复制之后的程度，避免从那些滞后时间超过一分钟的从节点读取。\n客户端记住最近更新时的时间戳，并附带到请求中，根据此信息，系统可以保证对该用户提供读服务时都应该至少包含了该时间戳的更新。如果不够新，则交给其他副本进行处理，要么等待直到副本接收到了最近的更新。\n如果副本分布在多数据中心，必须先把请求路由到主节点所在的数据中心。\n单调读 主要是解决用户看到了最新内容之后又读到了过期的内容，好像时间被回拨，此时需要单调读一致性。（出现这种情况主要是因为主从节点数据不一致或同步滞后导致的）\n解决方案：确保每个用户总是从固定的同一副本执行读取。（例如：基于用户Id进行哈希的方式选择副本，而不是随机选择）\n前缀一致性 在许多分布式数据库中，不同分区独立运行，因此不存在写入顺序。这就导致当用户从数据库中读取数据时，可能会看到数据库的某部分新值和另一部分旧值。\n一个解决方案是确保任何具有因果顺序关系的写入都交给一个分区来完成，但这种方案真是实现效率会大打折扣。\n","date":"2022-05-31T00:00:00Z","permalink":"http://localhost:1313/p/%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/","title":"数据复制"},{"content":"时代在要求我们写测试 因为软件变得越来越复杂，测试可以让我们在复杂的软件开发中稳步前行。另一方面软件测试可以让我们在长期的过程中不断回归，让每一步走的更稳。\n程序员圈子流传着一个关于测试的段子：** 每个程序员在修改代码时都希望有测试，而在写代码时，都不想写测试。**\n大部分程序员都不会写测试 很多程序员反对写测试，本质上的原因是因为他们不会写测试。\n你的代码质量真的高吗？ 经过测试的代码，质量会更高； 要想写好测试，代码本身质量也要高。 *** 如果你连测试都做不好，你对自己代码的信心从何而来呢？***\n学习写测试 *** 最好的办法就是跟着会写测试的人一起写一段时间 ***\n思考：可以查阅优秀的开源代码是如何写测试的。\nToDo项目的一些基本准备工作 一个项目的自动化； 对需求进行简单设计。 为什么需要自动化呢？简单来说是为了防止一些低级错误。\n*** 把核心的业务部分和命令行呈现的部分分开。***\n任务分解 从离我们需求最近的入口开始。\n*** 要想测试一个函数，一个函数最好是可测的。什么是可测的？就是通过函数的接口设计，我们给出特定的输入，它能给我们相应的输出。所以，一个函数最好是有返回值的。***\nFail Fast 原则 ** 一条设计规范：对于输入参数的检测，由入口部分代码进行处理。 ** ** 一条设计规范：Repository 的问题以运行时异常的形式抛出，业务层不需要做任何处理。**\n项目刚开始时，我们要准备哪些内容：\n项目的自动化； 针对需求进行初步的设计。 着手编写代码时，我们要怎么做呢？\n对要实现的需求进行任务分解； 在一个具体的需求任务中，我们可以从需求入口开始入手； 设计一个可测试的函数； 针对具体的函数，考虑测试场景； 针对具体的测试场景，将场景具象化成测试用例。 在梳理的过程中，我们还会针对一些统一的情况作出一些约定，成为项目整体的设计规范，比如，在这里我们约定：\n对于输入参数的检测，由入口部分代码进行处理； Repository 的问题以运行时异常的形式抛出，业务层不需要做任何处理。 在编码的过程中，我们也看到了：\n根据不断增加的需求，逐渐改动我们的设计，这就是演化式设计的基本做法； 我们对待测试也像对待代码一样，会消除代码中存在的一些坏味道。 ","date":"2022-05-30T00:00:00Z","permalink":"http://localhost:1313/p/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE/","title":"程序员的测试课"},{"content":"\r","date":"2022-04-12T00:00:00Z","permalink":"http://localhost:1313/p/netty/","title":"Netty"},{"content":" 本文是为我的年轻人（或任何新手）准备的，他们可以有效地使用git命令行，并简要介绍了我如何使用这些命令。 https://medium.com/@mmpatil34/11-git-commands-i-use-daily-9bbd7590c8eb\n1. git fetch origin 从特定的仓库拉取所有的branchs/tags, 这里的仓库是“origin”, 我每天从这个命令开始, 它可以让本地和远程仓库状态保持一致.\n2. git status 显示当前分支自上次提交到现在的文件改动列表,在切换分支、创建新分支、进行新更改或拉取更改之前, 此命令可以检查是否有文件需要被stash.\n3. git checkout git checkout -b \u0026lt;new branch name\u0026gt; origin/\u0026lt;source branch name\u0026gt; 从特定源分支创建一个新分支,这块的“origin”代表默认仓库. git checkout — — \u0026lt;name of the file\u0026gt; 当本地有文件变动时,可以使用这个命令丢弃当前改变,恢复文件到之前状态. git checkout \u0026lt;branch name\u0026gt; 切换本地到指定分支.\n4. git pull origin 将更改从远程分支拉到本地分支，并在更改兼容的情况下调用git merge。 git pull 和 git fetch的不同之处是: git pull = git fetch + git merge\n5. git add 文件修改完成后,就可以使用git add命令将文件添加到特定提交中,使用git status命令可以很方便的获取到要添加指定提交的文件名.\n6. git commit git commit -m \u0026quot;\u0026lt;提交内容的描述\u0026gt;\u0026quot; 提交本地改变,并指定和提交内容相关的描述.\n7. git push origin 将本地提交推送到远程存储库,这里的仓库是“origin”.\n8. git cherry-pick 1 2 3 a - b - c - d Master \\ e - f - g Feature 现在将提交f应用到master分支。\n1 2 3 4 5 6 # 切换到 master 分支 $ git checkout master # Cherry pick 操作 $ git cherry-pick f 上面的操作完成以后，代码库就变成了下面的样子。\n1 2 3 a - b - c - d - f Master \\ e - f - g Feature 1 git cherry-pick -m 1 \u0026lt;commit_id\u0026gt; 如果原始提交是一个合并节点，来自于两个分支的合并，那么 Cherry pick 默认将失败，因为它不知道应该采用哪个分支的代码变动。\n-m配置项告诉 Git，应该采用哪个分支的变动。它的参数parent-number是一个从1开始的整数，代表原始提交的父分支编号。\n上面命令表示，Cherry pick 采用提交commitHash来自编号1的父分支的变动。 一般来说，1号父分支是接受变动的分支（the branch being merged into），2号父分支是作为变动来源的分支（the branch being merged from）。\n9. git revert 引入一个新的提交来撤回已经push的提交.\n10. git reset — soft HEAD~1 撤消一次本地提交而不会丢失文件中的变更.\n11. git reset — hard HEAD~1 撤销一次本地提交并且丢弃文件中的变更. 希望对你有帮助. 感谢阅读😁\n","date":"2022-04-12T00:00:00Z","permalink":"http://localhost:1313/p/%E6%88%91%E6%AF%8F%E5%A4%A9%E4%BD%BF%E7%94%A8%E7%9A%8411%E4%B8%AAgit-commands/","title":"我每天使用的11个Git Commands"},{"content":"main.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package main import ( \u0026#34;context\u0026#34; \u0026#34;github.com/gorilla/mux\u0026#34; \u0026#34;github.com/txn2/txeh\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httputil\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; ) var hostArr = []string{\u0026#34;project-01\u0026#34;, \u0026#34;project-02\u0026#34;} const ( host = \u0026#34;api-dev.deveye.cn\u0026#34; proxyUrl = \u0026#34;https://api-dev.deveye.cn/\u0026#34; address = \u0026#34;127.0.0.1\u0026#34; ) func main() { hosts, err := txeh.NewHostsDefault() if err != nil { panic(err) } hosts.AddHosts(address, hostArr) log.Println(hosts.Save()) r := mux.NewRouter() r.Use(LoggingHandler, AuthHandler, RecoverHandler) r.PathPrefix(\u0026#34;/\u0026#34;).HandlerFunc(ReverseProxy) srv := \u0026amp;http.Server{ Addr: \u0026#34;:80\u0026#34;, Handler: r, } go func() { if err := srv.ListenAndServe(); err != nil { log.Println(err) } }() c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) \u0026lt;-c ctx, cancel := context.WithCancel(context.Background()) defer cancel() log.Println(srv.Shutdown(ctx)) hosts.RemoveHosts(hostArr) log.Println(hosts.Save()) log.Println(\u0026#34;shutting down\u0026#34;) os.Exit(0) } func ReverseProxy(w http.ResponseWriter, r *http.Request) { u, err := url.Parse(proxyUrl) if err != nil { log.Println(err) } proxy := httputil.NewSingleHostReverseProxy(u) r.Host = host proxy.ServeHTTP(w, r) } middleware.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 import ( \u0026#34;bytes\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) var loginUrl = proxyUrl + \u0026#34;login/sms\u0026#34; func LoggingHandler(next http.Handler) http.Handler { fn := func(w http.ResponseWriter, r *http.Request) { t1 := time.Now() next.ServeHTTP(w, r) t2 := time.Now() log.Printf(\u0026#34;[%s] %q %v\u0026#34;, r.Method, r.URL.String(), t2.Sub(t1)) } return http.HandlerFunc(fn) } func RecoverHandler(next http.Handler) http.Handler { fn := func(w http.ResponseWriter, r *http.Request) { defer func() { if err := recover(); err != nil { log.Printf(\u0026#34;Recover from panic: %+v\u0026#34;, err) http.Error(w, http.StatusText(500), 500) } }() next.ServeHTTP(w, r) } return http.HandlerFunc(fn) } func AuthHandler(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { token, err := getAccessToken() if err != nil { log.Fatalln(err) } r.Header.Set(\u0026#34;X-Auth-AppId\u0026#34;, \u0026#34;10003\u0026#34;) r.Header.Set(\u0026#34;X-Auth-Token\u0026#34;, token) next.ServeHTTP(w, r) }) } func getAccessToken() (string, error) { params := map[string]string{ \u0026#34;phone\u0026#34;: \u0026#34;15555555551\u0026#34;, \u0026#34;verifyCode\u0026#34;: \u0026#34;888888\u0026#34;, \u0026#34;codeId\u0026#34;: \u0026#34;111111\u0026#34;, } marshal, _ := json.Marshal(params) reader := bytes.NewReader(marshal) request, _ := http.NewRequest(\u0026#34;POST\u0026#34;, loginUrl, reader) request.Header.Add(\u0026#34;X-Auth-AppId\u0026#34;, \u0026#34;10003\u0026#34;) request.Header.Set(\u0026#34;content-type\u0026#34;, \u0026#34;application/json\u0026#34;) client := \u0026amp;http.Client{} do, err := client.Do(request) if err != nil { return \u0026#34;\u0026#34;, err } b, err := ioutil.ReadAll(do.Body) if err != nil { return \u0026#34;\u0026#34;, err } _ = do.Body.Close() result := \u0026amp;LoginResult{} if err := json.Unmarshal(b, result); err != nil { return \u0026#34;\u0026#34;, err } if result.ErrCode != \u0026#34;0\u0026#34; { return \u0026#34;\u0026#34;, errors.New(result.Message) } return result.Data.Token, nil } type LoginResult struct { ErrCode string Message string Data struct { Name string Token string Phone string } } ","date":"2022-04-07T00:00:00Z","permalink":"http://localhost:1313/p/go%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86quickstart/","title":"go反向代理quickstart"},{"content":"Prometheus快速入门 一、背景 我们日常开发和运维中，需要监控一些数据，根据这些数据进行分析或者应对策略，例如以下几个维度：\n场景 描述 硬件系统 温度，硬件故障 系统监控 CPU，内存，磁盘，网卡流量，TCP状态，进程数 应用监控 Nginx，Tomcat，PHP，MySQL，Redis 等 日志监控 系统日志，服务日志，访问日志，错误日志 安全监控 WAF，敏感文件监控 API监控 可用性，接口请求，响应时间 业务监控 例如电商网站，每分钟产生多少订单，注册多少用户，多少活跃用户，推广活动效果 流量分析 根据流量获取用户相关信息，例如用户地理位置，某页面访问状况，页面停留时间等 二、Prometheus是什么? Prometheus 是由 SoundCloud 开发的开源监控报警系统和时序列数据库(TSDB)。\nPrometheus由Go语言编写而成，采用Pull方式获取监控信息，并提供了多维度的数据模型和灵活的查询接口。 Prometheus不仅可以通过静态文件配置监控对象，还支持自动发现机制，能通过Kubernetes、Consl、DNS等多种方式动态获取监控对象。 在数据采集方面，借助Go语言的高并发特性，单机Prometheus可以采取数百个节点的监控数据；在数据存储方面，随着本地时序数据库的不断优化，单机Prometheus每秒可以采集一千万个指标，如果需要存储大量的历史监控数据，则还支持远程存储。\n三、为什么需要Prometheus? 对于运维人员来说，他们需要监控机器的 CPU、内存、硬盘的使用情况，以此来保证运行在机器上的应用的稳定性。 对于研发人员来说，他们关注某个异常指标的变化情况，从而来保证业务的稳定运行。 对于产品或运营来说，他们更关心产品层面的事情，例如：某个活动参加人数的增长情况，活动积分的发放情况。 例如：运维希望在 CPU 达到 80% 的时候给值班的运维人员发送邮件，产品希望活动积分发放数量超过 10 万的时候发送告警邮件。这些都可以通过 Prometheus 实现。\n对于流量不是很大的系统来说，出现几分钟的故障可能造成不了多少损失。但是对于像淘宝、美团、字节跳动这样的巨无霸来说，宕机 1 分钟损失的金额可能就是几百万！\n所以弄清楚此时此刻系统的运行是否正常？各项业务指标是否超过阈值？这些问题是每个经验丰富的研发人员所需要关注的事情！\n那么如何监控你的系统？如何得知系统目前是正常还是异常？甚至如何预知未来一段时间系统可能出问题？Prometheus 正是这么一套数据监控解决方案。它能让你随时掌控系统的运行状态，快速定位出现问题的位置，快速排除故障。\n只要按照 Prometheus 的方式来做，按部就班地学习和部署，我们就可以监控机器的 CPU、内存等资源的使用情况、Java 应用的运行情况以及业务各项指标的实时数据。\n而通过 Prometheus 则可以直接部署使用，并且其与 Grafana 配套使用可以呈现出非常多样化的图表配置。对于中小规模的团队来说，可以极大地减少成本，加快研发速度。\n而对于个人来讲，掌握 Prometheus 可以增加你当 leader 的竞争力。 毕竟如果一个研发对自己的系统运行状况都不了解，那么他怎么做 leader，怎么带领一个团队往前冲呢？\n四、Prometheus Quickly Start 1、实现目标 实现一个Web服务接口请求速率状况的监控功能，当接口请求增长速率超出设定的阈值时，发送钉钉消息通知给研发运维人员。\n2、服务搭建 这里使用Docker 搭建 prometheus、alertmanager和dingtalk.\n① 创建对应文件目录：\n1 2 3 4 mkdir -p ~/prometheus/ \u0026amp;\u0026amp; cd ~/prometheus/ \u0026amp;\u0026amp; touch prometheus.yml mkdir -p ~/prometheus/groups/nodegroups/ \u0026amp;\u0026amp; cd ~/prometheus/groups/nodegroups/ \u0026amp;\u0026amp; touch node.json mkdir -p ~/prometheus/rules/ \u0026amp;\u0026amp; cd ~/prometheus/rules/ \u0026amp;\u0026amp; touch http-rate.rules mkdir -p ~/prometheus/alertmanager \u0026amp;\u0026amp; /prometheus/alertmanager \u0026amp;\u0026amp; touch alertmanager.yml ② 配置对应文件\nprometheus.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: \u0026#39;codelab-monitor\u0026#39; # A scrape configuration containing exactly one endpoint to scrape: # Here it\u0026#39;s Prometheus itself. scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: \u0026#39;prometheus\u0026#39; # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] - job_name: \u0026#39;prometheus-sample\u0026#39; # 可以在不用重启的情况下热加载配置文件 file_sd_configs: - files: [\u0026#39;/usr/local/prometheus/groups/nodegroups/*.json\u0026#39;] # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: - 192.168.220.121:9093 rule_files: - \u0026#34;/usr/local/prometheus/rules/*.rules\u0026#34; node.json\n1 2 3 4 5 6 7 8 9 [ { \u0026#34;targets\u0026#34;: [\u0026#34;192.168.220.121:8080\u0026#34;,\u0026#34;192.168.220.121:8081\u0026#34;], \u0026#34;labels\u0026#34;: { \u0026#34;instance\u0026#34;: \u0026#34;vm-192.168.220.121\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;node-service\u0026#34; } } ] http-rate.rules\n1 2 3 4 5 6 7 8 9 10 groups: - name: http-rate rules: - alert: http-rate expr: rate(prometheus_sample_hello_world_count[1m]) \u0026gt; 100 for: 15s labels: severity: 1 annotations: summary: \u0026#34;{{ $labels.instance }} HTTP 1min请求增长率超过100%\u0026#34; alertmanager.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # 全局配置项 global: resolve_timeout: 5m # 处理超时时间，默认为5min # 定义路由树信息 route: group_by: [alertname] # 报警分组依据 receiver: ops_notify # 设置默认接收人 group_wait: 30s # 最初即第一次等待多久时间发送一组警报的通知 group_interval: 60s # 在发送新警报前的等待时间 repeat_interval: 1h # 重复发送告警时间。默认1h routes: - receiver: ops_notify # 基础告警通知 group_wait: 10s match_re: alertname: 实例存活告警|磁盘使用率告警 # 匹配告警规则中的名称发送 # 定义基础告警接收者 receivers: - name: ops_notify webhook_configs: - url: http://192.168.220.121:8060/dingtalk/webhook/send send_resolved: true # 警报被解决之后是否通知 # 一个inhibition规则是在与另一组匹配器匹配的警报存在的条件下，使匹配一组匹配器的 警报失效的规则。两个警报必须具有一组相同的标签。 inhibit_rules: - source_match: severity: \u0026#39;critical\u0026#39; target_match: severity: \u0026#39;warning\u0026#39; equal: [\u0026#39;alertname\u0026#39;, \u0026#39;dev\u0026#39;, \u0026#39;instance\u0026#39;] config.yml\n1 2 3 4 5 targets: webhook: url: https://oapi.dingtalk.com/robot/send?access_token=xxx # secret for signature secret: SECxxx docker 创建服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 docker run --name prometheus -d -p 9090:9090 \\ -v ~/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \\ -v ~/prometheus/groups/:/usr/local/prometheus/groups/ \\ -v ~/prometheus/rules/:/usr/local/prometheus/rules/ \\ prom/prometheus:latest docker run --name alertmanager -d -p 9093:9093 \\ -v ~/prometheus/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml \\ prom/alertmanager:latest docker run --name dingtalk -d -p 8060:8060 \\ -v ~/prometheus/dingtalk/config.yml:/etc/prometheus-webhook-dingtalk/config.yml \\ timonwong/prometheus-webhook-dingtalk 3、客户端代码 这里使用Go语言编写的一个简易的Web服务，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/prometheus/client_golang/prometheus\u0026#34; \u0026#34;github.com/prometheus/client_golang/prometheus/promhttp\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) var port = flag.Int(\u0026#34;p\u0026#34;, 8080, \u0026#34;-port 8080\u0026#34;) func main() { flag.Parse() prometheus.Register(httpCount) http.Handle(\u0026#34;/metrics\u0026#34;, promhttp.Handler()) http.HandleFunc(\u0026#34;/hello\u0026#34;, HelloWorld) log.Fatalln(http.ListenAndServe(fmt.Sprintf(\u0026#34;:%d\u0026#34;, *port), nil)) } var httpCount = prometheus.NewCounter( prometheus.CounterOpts{ Name: \u0026#34;prometheus_sample_hello_world_count\u0026#34;, Help: \u0026#34;hello world count!\u0026#34;, }, ) func HelloWorld(w http.ResponseWriter, r *http.Request) { httpCount.Inc() w.Write([]byte(\u0026#34;Hello World!\u0026#34;)) } 这里我们启动两个节点：\n1 2 go run main -p 8080 go run main -p 8081 4、Prometheus Dashboard 打开仪表盘：http://localhost:9090/targets，我们可以看到我们的两个节点已经是up状态了。\n下面我们使用ab 工具模拟接口访问，使请求速度超过我们设定的阈值，此时alertmanages会给我们钉钉进行通知。\n1 ab -n 1000 -c 5 http://localhost:8080/hello 我可以查看Prometheus控制台，查看消息警告发送情况，此时，我们的钉钉已经收到通知警告：\n5、总结 我们通过一个简单的实验，实现了一个接口请求速率监控的例子，实际业务中我们还可以做更多服务监控的功能。也可以结合Grafana进行Dashbords数据报表展示等功能。同时可以监控服务器、JVM、k8s等等，当服务按照我们设置的规则达到阈值时通知到我们，我们可以在第一时间做应对处理，避免造成不必要的损失。\n","date":"2022-02-28T00:00:00Z","permalink":"http://localhost:1313/p/prometheus%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","title":"Prometheus快速入门"},{"content":"坐中静，破焦虑之贼——可以用冥想打坐等方法让自己回到当下，人之所以会焦虑是基于过去的经验对未来产生的恐惧，能够活在当下的人不会焦虑。把每一天每一刻过好，人生自然就会好。 舍中得，破欲望之贼——人的痛苦多来自于欲望，即为贪婪和占有，也是一种匮乏的表现，如果能够学会舍，则内心越来越丰盛。没钱的时候把勤舍出去即为天道酬勤；有钱的时候把钱舍出去人就来了，是为轻财聚人；有人的时候，把爱舍出去，成功便有了；事业有成的时候，把智慧舍出去，喜悦就来了，这就是德行天下。 事上练，破犹豫之贼——这里讲的大概是王阳明的知行合一。光懂了很多道理是过不好这一生的，唯有践行其中的道理才能真正成事，只要想到就去做，犹豫纠结之贼就能破，达到知行合一的最高境界，则万事可成。\n作者：数中有术作者 链接：https://www.zhihu.com/question/448566584/answer/1898949098 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n","date":"2022-02-21T00:00:00Z","permalink":"http://localhost:1313/p/%E5%BF%83%E4%B8%AD%E9%9C%80%E7%A0%B4%E9%99%A4%E7%9A%84%E4%B8%89%E7%A7%8D%E8%B4%BC/","title":"心中需破除的三种贼"},{"content":" 关于MySQL出现lock wait timeout exceeded; try restarting transaction 的解决方案。 1 2 3 select * from information_schema.innodb_trx; kill $trx_mysql_thread_id; ","date":"2021-09-26T00:00:00Z","permalink":"http://localhost:1313/p/mysql%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/","title":"MySQL常见问题处理"},{"content":"以终为始 遇到问题不妨倒着去思考\n任务分解 埃隆马斯克SpaceX 的计划，本质上就是把一件很困难实现的事情去做任务分解，使每件任务可执行化。 1 2 3 4 如何降低火箭发射成本 1. 造一个能容纳100人的火箭 2. 实现火箭回收 3. .... 大师程序员都是懂的去做任务分解，分解的力度是可执行\n多写单元测试，代码小步提交\n","date":"2021-04-13T00:00:00Z","permalink":"http://localhost:1313/p/10x%E7%A8%8B%E5%BA%8F%E5%91%98%E6%80%BB%E7%BB%93/","title":"10x程序员总结"},{"content":" 序号 名称 状态 1 《专栏: 10x程序员工作法》 已完成 2 《Java并发编程的艺术》 进行中 3 《高效能人士的七个习惯》 已完成 4 《自控力》 已完成 5 《关键对话》 进行中 ","date":"2021-04-09T00:00:00Z","permalink":"http://localhost:1313/p/%E9%98%85%E8%AF%BB%E6%B8%85%E5%8D%95/","title":"阅读清单"},{"content":" 原文地址: http://antirez.com/news/112\n坊间流传着“十倍程序员”的传说，所谓“十倍程序员”是指在同样时间内可以做“普通”程序员十倍的工作的程序员，而所谓“普通”是指那些擅长自己的领域，但不具有“十倍程序员”那样特殊魔力的程序员。更准确地说，普通程序员就是指那些具有平均编程效率的专业程序员。\n在程序员群体中，对于“十倍程序员”的存在持有极度分化的观点：一些人认为这样的人绝不存在，另一些人则认为不仅存在，而且甚至存在“百倍程序员”。\n如果你认为编程是一项线性工作（产出与劳动时间成正比的工作），那么显然“十倍程序员”是一种不合理的存在。一个跑步运动员不可能比对手跑得快十倍，一个建筑工人也不可能在同等时间建造十倍于别人的东西。然而，编程实际上是一项特殊的“设计”工作。此处设计不单指架构师的工作。即便不是项目的整体设计，当工程师具体实现它的时候，依然需要低层的实现策略的设计。\n在我看来，程序的设计和实现不是一项线性工作。经验、代码能力、知识、对不重要事项的辨识能力都是不易量化的能力，这些能力的结合在程序开发中发挥重要作用，使程序员更高效。特别是当一个程序员需要全程参与到项目的设计与实现时，这些能力的优势更加明显。\n越是以结果为导向的任务越能激发高效程序员的能力。因为在结果导向的任务中，高效的程序员能够找到自己的方式，用更少的投入达到同样的效果。他们可以从顶层改变目标的实现路径，有时甚至直接去掉不必要的模块，来减少工作量而不影响目标的达成。而相对要求严格的项目，则会使这种效应减弱，因为程序员不得不受到诸如“使用某某工具”，“通过某某算法”的限制。虽然如此，高效程序员在这种多限制的情况下仍有其优势：他们可以发掘细节处优化实现的办法。\n在我二十年的编程生涯中，始终观察我身边的程序员，无论我的同事、学徒，还是Redis或者其他项目的贡献者，以指导他们高效地达到既定目标。很多人说我是个很“快”的程序员。鉴于我不是个工作狂，所以我想以我为例来说明如何高效编程。\n以下是我认为影响程序员工作效率的最主要因素：\n纯编程能力：不写一行多余代码 程序员的纯编程能力是程序员水平的最直接表现。在解决实际问题时候，程序员经常会被要求实现项目的某一个子模块，一个函数或者一个算法等等。令人惊讶的是，我发现在这个过程中，很少有人能够做到用最少的命令高效地完成任务。我甚至发现在很多团队中，竟然存在会忘记使用排序算法的不称职的程序员，这让他们甚至无法胜过虽然缺乏实践经验但理论完备的毕业生。\n解读：强调的是过硬编码能力\n经验：踩在前人的肩膀上 所谓经验，我指的是重复出现的任务的成熟解决方案。一个有经验的程序员知道如何处理各种任务。这可以避免重复设计，更重要的是可以避免设计错误，设计错误是程序员效率的最大敌人。\n解读：强调积累及思考的重要性\n专注：高效利用时间 对于任何事情，时间的有效利用都至关重要，许多内在和外在的因素都会导致程序员丧失专注度。内在因素包括拖延症、没有兴趣、缺乏经验、睡眠短缺等。外在因素包括频繁的会议、工作环境、同事的干扰等。***提高专注度、避免打扰能够提高编程效率，***这很好理解。有时，为了专注，需要狠下心来，采取较为极端的措施。比如邮件，虽然都会看，但只回复很少的一部分。\n解读：专注\n不要吝惜时间设计：防止推倒重来 很多时候，程序员非常不情愿看到的一种情况是，需要在一些无关紧要的功能上浪费大量的时间，但你又不得不去将这个无关紧要的功能实现，因为它牵扯着这个项目的主要功能。这种时候，就需要反思，在顶层设计的时候是否考虑周全。详细而缜密的顶层设计能够减少上述情况的发生，即降低模块间的耦合性。对于项目的设计者来说，意识到每一个细小的模块都有可能成为项目的瓶颈，这很重要。对于项目而言，最终的目标是合理的时间做最大的产出，那么实施重点就应该放在项目最主要的模块上。拿我设计Disque（一个开源的分布式消息队列）为例，我意识到只要提供最优的消息排列方式，至于项目其他锦上添花的方面都可以后续慢慢补充，例如，可用性、查询语言、客户端交互、简易性及系统性能。\n解读：擒贼先擒王，重设计\n简洁性：避免细节错误才是程序简洁的根本 简洁性意味着很多。为了理解什么是简洁性，首先来看看究竟可以多复杂？我相信导致复杂性有两个罪魁祸首，除了上面所说的不愿意花费过多的时间在设计上，还有一个是在设计过程中错误的累积。\n思考一下程序实施的过程，所谓失之毫厘，谬以千里。一个初始的设计错误可能不会导致所在功能的重新设计，但可能会导致开发者需要在其他功能上做大量的工作来应对这个错误。因此，项目一步一步走向复杂和低效。\n简洁性需要一步一步实现。程序员可以从最直接可靠的解决方式开始入手，用尽可能简单的方式实现功能，之后随着经验和编程能力的提高，程序员就有能力去优化设计了。\n每次遇到不得不采取复杂的解决的方案的情况，开发者都应该花些时间想想如何避免这种情况的发生。只有在考虑了各种不同的方式，发现不得不走这条道路的时候，才继续在这个方向上前进。\n解读：\n完美主义：高效产出的最大阻碍 完美主义有两种类型，一种是追求至高性能的工程师文化，一种要符合个人趣向的执拗。两种情况都妨碍到程序员快速发布项目。完美主义和对外界评价的在乎会使程序员过多地将关注点放在一些细枝末节上，进而主观忽视项目的关键特性，例如程序的稳健性、简洁性、及是否能够按时交付。\n解读：避免完美主义，讲究实际\n知识：某些关键问题还是要依靠理论解决 当处理复杂的任务时：数据结构知识、对计算能力的极限的了解、对针对某个任务最行之有效的小众算法的了解，会帮助我们解决这些任务。对于开发者而言，对所有问题的所有解决方案都了如指掌这不现实，但对于某类问题的多数潜在解决方案都有所了解是必须的。例如，容许一定错误率，考虑概率集合基数估计量，可以设计一个优化的流的元素计数算法，避免复杂，缓慢，空间效率低下的缺点。\n解读：理论知识的重要性\n底层：熟悉计算机的脾性 即便我们使用的是高级语言，但不了解计算机的内部运行机制仍然会导致一些问题。有时系统会出现涉及到底层问题的工具或算法错误，导致整个系统的重新设计实施。深入理解C语言、CPU运算机理和操作系统内核会避免我们遇到在项目后期“推倒重来”的情况。\n解读：底层的重要性\nDebug能力：无需多言 寻找Bug总是非常耗费时间的。擅长发现、定位并合理地解决Bug，以及在编程过程中尽可能简化程序以减少Bug，这些素质将极大地提高程序员的编程效率\n解读：实战快速定位能力\n总结 对于我来说，一个拥有以上素质的程序员，能表现出“十倍”于平庸程序员的效率是绝不意外的。往往，他们在项目开始的可行性研究阶段就能做出正确的决策，这样一来，数倍于常人的效率是很容易实现的。这种方式我称之为“取巧编程”，意思是在开发过程中的每一步都选择最优化的解决方案，花费最少的努力获得最大的用户体验。\n","date":"2021-04-08T00:00:00Z","permalink":"http://localhost:1313/p/10x%E7%A8%8B%E5%BA%8F%E5%91%98/","title":"10x程序员"},{"content":" 转载自: https://www.cnblogs.com/sanzao/p/10528677.html\n本文主要结合 java.lang.Thread 源码，梳理 Java 线程的整体脉络；\n一、线程概述 对于 Java 中的线程主要是依赖于系统的 API 实现的，这一点可以从 java.lang.Thread；源码中关键的方法都是 native 方法看出，也可以直接查看 OpenJDK 源码看出来，这一点后面还会讲到；对于 JDK1.8 而言，他的 Windows 版和 Linux 版使用的都是 1:1 线程模型，即系统内核线程和轻量级进程的比是 1:1；\n内核线程（Kernel-Level Thread，KLT）：是由操作系统内核（Kernel）直接支持的线程，这种线程由内核来完成切换，内核通过调度器（Schedule）进行调度，并负责将线程的任务映射到各个处理器上； 轻量级进程（Light Weight Process，LWP）：程序可以直接使用的一种内核线程高级接口，也就是我们通常意义上的线程； 如图所示：\n优点：\n由内核线程的支持，每个线程都成为一个独立的调度单元，即线程之间不会相互阻塞影响；使用内核提供的线程调度功能及处理器映射，可以完成线程的切换，并将线程的任务映射到其他处理器上，充分利用多核处理器的优势，实现真正的并行。 缺点：\n同时由于基于内核线程实现，线程的创建、关闭、同步等操作都需要系统调用；需要在用户态和内核态之间切换，代价相对较高； 另外每个线程都需要消耗一定的内核资源，如内核线程的栈空间，所以系统支持的轻量级进程是有限的； 二、线程状态 Java 线程的整个生命周期可能会经历以下5中状态，如图所示：\n新建（New）：新建后未启动的线程； 运行（Runnable）：包括运行中（Running）和就绪（Ready）两种状态；也就是正在运行，或者等待 CPU 分配执行时间； 等待（Waiting）：无限期的等待其他线程显示唤醒； 超时等待（Timed_Waiting）：一定时间内没有被其他线程唤醒，则由系统自动唤醒； 阻塞（Blocked）：等待获取排它锁； 终止（Terminated）：运行终止； 三、源码分析 1. native注册 1 2 3 4 5 /* Make sure registerNatives is the first thing \u0026lt;clinit\u0026gt; does. */ private static native void registerNatives(); static { registerNatives(); } 这段代码在很多地方都出现过，比如：\n1 2 3 java.lang.System java.lang.Object java.lang.Class 其作用就是在使用 JNI 时需要向 JVM 注册，其方法名默认为 Java_\u0026lt;fully qualified class name\u0026gt;_method；但是如果觉得这样的名字太长，这是就可以使用 registerNatives() 向 JVM 注册任意的函数名；\nThread 中的 native 方法有：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 private native void start0(); private native void stop0(Object o); public final native boolean isAlive(); private native void suspend0(); private native void resume0(); private native void setPriority0(int newPriority); public static native void yield(); public static native void sleep(long millis) throws InterruptedException; public static native Thread currentThread(); public native int countStackFrames(); private native void interrupt0(); private native boolean isInterrupted(boolean ClearInterrupted); public static native boolean holdsLock(Object obj); private native static Thread[] getThreads(); private native static StackTraceElement[][] dumpThreads(Thread[] threads); private native void setNativeName(String name); 其对应 JVM 源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // openjdk\\jdk\\src\\share\\native\\java\\lang\\Thread.c static JNINativeMethod methods[] = { {\u0026#34;start0\u0026#34;, \u0026#34;()V\u0026#34;, (void *)\u0026amp;JVM_StartThread}, {\u0026#34;stop0\u0026#34;, \u0026#34;(\u0026#34; OBJ \u0026#34;)V\u0026#34;, (void *)\u0026amp;JVM_StopThread}, {\u0026#34;isAlive\u0026#34;, \u0026#34;()Z\u0026#34;, (void *)\u0026amp;JVM_IsThreadAlive}, {\u0026#34;suspend0\u0026#34;, \u0026#34;()V\u0026#34;, (void *)\u0026amp;JVM_SuspendThread}, {\u0026#34;resume0\u0026#34;, \u0026#34;()V\u0026#34;, (void *)\u0026amp;JVM_ResumeThread}, {\u0026#34;setPriority0\u0026#34;, \u0026#34;(I)V\u0026#34;, (void *)\u0026amp;JVM_SetThreadPriority}, {\u0026#34;yield\u0026#34;, \u0026#34;()V\u0026#34;, (void *)\u0026amp;JVM_Yield}, {\u0026#34;sleep\u0026#34;, \u0026#34;(J)V\u0026#34;, (void *)\u0026amp;JVM_Sleep}, {\u0026#34;currentThread\u0026#34;, \u0026#34;()\u0026#34; THD, (void *)\u0026amp;JVM_CurrentThread}, {\u0026#34;countStackFrames\u0026#34;, \u0026#34;()I\u0026#34;, (void *)\u0026amp;JVM_CountStackFrames}, {\u0026#34;interrupt0\u0026#34;, \u0026#34;()V\u0026#34;, (void *)\u0026amp;JVM_Interrupt}, {\u0026#34;isInterrupted\u0026#34;, \u0026#34;(Z)Z\u0026#34;, (void *)\u0026amp;JVM_IsInterrupted}, {\u0026#34;holdsLock\u0026#34;, \u0026#34;(\u0026#34; OBJ \u0026#34;)Z\u0026#34;, (void *)\u0026amp;JVM_HoldsLock}, {\u0026#34;getThreads\u0026#34;, \u0026#34;()[\u0026#34; THD, (void *)\u0026amp;JVM_GetAllThreads}, {\u0026#34;dumpThreads\u0026#34;, \u0026#34;([\u0026#34; THD \u0026#34;)[[\u0026#34; STE, (void *)\u0026amp;JVM_DumpThreads}, {\u0026#34;setNativeName\u0026#34;, \u0026#34;(\u0026#34; STR \u0026#34;)V\u0026#34;, (void *)\u0026amp;JVM_SetNativeThreadName}, }; 其具体实现可以查看\n1 2 openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.h openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.cpp 2. 构造方法和成员变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 public class Thread implements Runnable { private volatile String name; // 线程名称，如果没有指定，就通过 Thread-线程序列号 命名 private int priority; // 线程优先级，1-10 默认与父线程优先级相同(main 线程优先级为 5) private boolean daemon = false; // 是否是守护线程 private Runnable target; // Runnable 对象 private ThreadGroup group; // 所属线程组 ThreadLocal.ThreadLocalMap threadLocals = null; // 线程本地变量 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; // 可继承的线程本地变量 private long tid; // 线程 tid ... public Thread() { init(null, null, \u0026#34;Thread-\u0026#34; + nextThreadNum(), 0); } public Thread(Runnable target) { init(null, target, \u0026#34;Thread-\u0026#34; + nextThreadNum(), 0); } public Thread(ThreadGroup group, Runnable target) { init(group, target, \u0026#34;Thread-\u0026#34; + nextThreadNum(), 0); } public Thread(String name) { init(null, null, name, 0); } public Thread(ThreadGroup group, String name) { init(group, null, name, 0); } public Thread(Runnable target, String name) { init(null, target, name, 0); } public Thread(ThreadGroup group, Runnable target, String name) { init(group, target, name, 0); } public Thread(ThreadGroup group, Runnable target, String name, long stackSize) { init(group, target, name, stackSize); } private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(\u0026#34;name cannot be null\u0026#34;); } this.name = name; Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) { if (security != null) { g = security.getThreadGroup(); } if (g == null) { g = parent.getThreadGroup(); } } g.checkAccess(); if (security != null) { if (isCCLOverridden(getClass())) { security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); } } g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (inheritThreadLocals \u0026amp;\u0026amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); this.stackSize = stackSize; tid = nextThreadID(); } ... } 可以看到左右的构造方法最终都会调用 init()；并初始化所属线程组、名字、 Runnable、栈大小等信息；整个过程相当于配置了一个线程工厂，此时只是初始化了所有的配置，线程还没有真正创建，当然资源同样也还没有分配，只有在调用 start() 的时候线程才会真正创建；\n此外可以看到线程创建过程中会有很多的权限检查，例如：\n1 2 3 4 5 6 SecurityManager security = System.getSecurityManager(); if (security != null) { if (isCCLOverridden(getClass())) { security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); } } 通常情况下权限的检查默认是没有开启的，所以 security 一直都是 null ；这里需要在启动 JVM 的时候指定 -Djava.security.manager ；当然也可以指定特定的 SecurityManager；但是在开启的时候很可能会遇到类似：java.security.AccessControlException: access denied ；权限检查失败的错误；\n此时可以在 jre\\lib\\security\\java.policy 中添加相应的权限；或者直接开启所有权限 permission java.security.AllPermission;\n1 2 3 4 5 6 7 8 9 10 11 // jre\\lib\\security\\java.policy grant { permission java.lang.RuntimePermission \u0026#34;stopThread\u0026#34;; permission java.net.SocketPermission \u0026#34;localhost:0\u0026#34;, \u0026#34;listen\u0026#34;; permission java.util.PropertyPermission \u0026#34;java.version\u0026#34;, \u0026#34;read\u0026#34;; ... permission java.security.AllPermission; }; 3. start 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public synchronized void start() { if (threadStatus != 0) throw new IllegalThreadStateException(); group.add(this); boolean started = false; try { start0(); started = true; } finally { try { if (!started) { group.threadStartFailed(this); } } catch (Throwable ignore) { // } } } private native void start0(); 可以看到这是一个同步方法，并且同一个线程不能启动两次；这里首先将线程加入对应的线程组，再真正创建线程，如果创建失败就在线程组中标记；对应的这个 native 方法 start0 ，的源码同样可以查看 openjdk\\hotspot\\src\\share\\vm\\prims\\jvm.cpp，这里就不详细介绍了；\n4. exit 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 private void exit() { if (group != null) { group.threadTerminated(this); group = null; } /* Aggressively null out all reference fields: see bug 4006245 */ target = null; /* Speed the release of some of these resources */ threadLocals = null; inheritableThreadLocals = null; inheritedAccessControlContext = null; blocker = null; uncaughtExceptionHandler = null; } exit 方法则是由系统调用，在 Thread 销毁前释放资源；\n5. 弃用方法 在源码里面还有几个弃用的方法：\n1 2 3 public final void stop() { } // 停止线程 public final void suspend() { } // 暂停线程 public final void resume() { } // 恢复线程 stop：停止线程会导致它解锁已锁定的所有监视器，从而产生同步问题，因为它本质上是不安全的。 suspend：暂停线程容易出现死锁，如果目标线程在监视器上保持锁定，那么在恢复目标线程之前，任何线程都无法访问此资源。 resume：恢复线程同样容易出现死锁， 如果 A 线程在恢复 B 线程之前锁定监视器，然后在调用 resume 恢复 B，此时 B 会尝试再次获取锁，这样就会导致死锁。 四、线程通讯 其实所有的多线程问题，其本质都是线程之间的通讯问题，也有的说是通讯和同步两个问题（线程间操作的顺序）；但我觉得同步仍然是线程之间通过某种方式进行通讯，确定各自执行的相对顺序；所以仍然可以算作是一种通讯问题；这里线程之间的通讯问题可以分成两种：\n共享变量，类似锁对象、volatile、中断等操作都可以算是共享变量通讯； 消息传递，类似 wait\\notify、管道等则可以算是通过消息直接传递通讯； 下面我们将介绍和 Thread 类直接相关的几种通讯，关于锁的部分之后的博客还会详细介绍；\n1. wait\\notify 机制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @Slf4j public class WaitNotify { private static boolean flag = true; private static final Object LOCK = new Object(); public static void main(String[] args) throws Exception { Thread waitThread = new Thread(new Wait(), \u0026#34;WaitThread\u0026#34;); waitThread.start(); TimeUnit.SECONDS.sleep(1); Thread notifyThread = new Thread(new Notify(), \u0026#34;NotifyThread\u0026#34;); notifyThread.start(); } private static class Wait implements Runnable { @Override public void run() { // 加锁，拥有lock的Monitor synchronized (LOCK) { // 当条件不满足时，继续wait，同时释放了lock的锁 while (flag) { try { log.info(\u0026#34;flag is true. wait\u0026#34;); LOCK.wait(); } catch (InterruptedException e) { } } // 条件满足时，完成工作 log.info(\u0026#34;flag is false. running\u0026#34;); } } } private static class Notify implements Runnable { @Override public void run() { // 加锁，拥有lock的Monitor synchronized (LOCK) { // 获取lock的锁，然后进行通知，通知时不会释放lock的锁， // 直到当前线程释放了lock后，WaitThread才能从wait方法中返回 log.info(\u0026#34;hold lock. notify\u0026#34;); LOCK.notify(); flag = false; SleepUtils.second(5); } // 再次加锁 synchronized (LOCK) { log.info(\u0026#34;hold lock again. sleep\u0026#34;); SleepUtils.second(5); } } } } // 打印：\n1 2 3 4 [13 21:18:18,533 INFO ] [WaitThread] WaitNotify - flag is true. wait [13 21:18:19,533 INFO ] [NotifyThread] WaitNotify - hold lock. notify [13 21:18:24,535 INFO ] [NotifyThread] WaitNotify - hold lock again. sleep [13 21:18:29,536 INFO ] [WaitThread] WaitNotify - flag is false. running 2. join 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @Slf4j public class Join { public static void main(String[] args) throws Exception { Thread previous = Thread.currentThread(); for (int i = 0; i \u0026lt; 5; i++) { // 每个线程拥有前一个线程的引用，需要等待前一个线程终止，才能从等待中返回 Thread thread = new Thread(new Domino(previous), String.valueOf(i)); thread.start(); previous = thread; } TimeUnit.SECONDS.sleep(5); log.info(\u0026#34;terminate.\u0026#34;); } private static class Domino implements Runnable { private Thread thread; public Domino(Thread thread) { this.thread = thread; } @Override public void run() { try { thread.join(); } catch (InterruptedException e) { } log.info(\u0026#34;terminate.\u0026#34;); } } } // 打印：\n1 2 3 4 5 6 [13 21:27:27,573 INFO ] [main] Join - terminate. [13 21:27:27,574 INFO ] [0] Join - terminate. [13 21:27:27,574 INFO ] [1] Join - terminate. [13 21:27:27,574 INFO ] [2] Join - terminate. [13 21:27:27,574 INFO ] [3] Join - terminate. [13 21:27:27,574 INFO ] [4] Join - terminate. 3. interrupt 以上 wait\\notify、join 都比较简单，大家直接看代码应该就能理解；但是 interrupt 机制 则比较复杂一点，我们先从源码分析；\ninterrupt 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 private volatile Interruptible blocker; private final Object blockerLock = new Object(); // Set the blocker field; invoked via sun.misc.SharedSecrets from java.nio code void blockedOn(Interruptible b) { synchronized (blockerLock) { blocker = b; } } public void interrupt() { if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) { Interruptible b = blocker; if (b != null) { interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; } } interrupt0(); } private native void interrupt0(); 在 Thread 的源码上有详细的注释，以下我简单翻译：\n如果线程处于 WAITINF、TIMED_WAITING （正阻塞于 Object 类的 wait()、wait(long)、wait(long, int)方法，或者 Thread 类的 join()、join(long)、join(long, int)、sleep(long)、sleep(long, int)方法），则该线程的中断状态将被清除，并收到一个 java.lang.InterruptedException； 如果线程正阻塞于 InterruptibleChannel 上的 I/O 操作，则该通道将被关闭，同时该线程的中断状态被设置，并收到一个java.nio.channels.ClosedByInterruptException； 如果线程正阻塞于 java.nio.channels.Selector 操作，则该线程的中断状态被设置，同时它将立即从选择操作返回，并可能带有一个非零值，其效果同 java.nio.channels.Selector.wakeup() 方法一样； 如果上述条件都不成立，则该线程的中断状态将被设置； 其中 Interruptible blocker 就是在 NIO 操作的时候通过 sun.misc.SharedSecrets 设置的（其效果同反射，但是不会生成其他对象，也就是不会触发 OOM）；\ninterrupted 、isInterrupted 方法：\n1 2 3 4 5 6 7 8 9 public static boolean interrupted() { return currentThread().isInterrupted(true); } public boolean isInterrupted() { return isInterrupted(false); } private native boolean isInterrupted(boolean ClearInterrupted); 可以很清楚的看到他们都是通过 isInterrupted(boolean ClearInterrupted) 方法实现的，但是 interrupted 会清除中断状态，而 isInterrupted 则不会清除；\n以上 interrupt 机制 就通过设置 interrupt flag，查询中断状态，以及中断异常构成了一套完整的通讯机制；也可以看作是通过 interrupt flag 共享变量实现的，下面我们简单举例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @Slf4j public class Interrupted { public static void main(String[] args) throws Exception { // sleepThread不停的尝试睡眠 Thread sleepThread = new Thread(new SleepRunner(), \u0026#34;SleepThread\u0026#34;); sleepThread.setDaemon(true); // busyThread不停的运行 Thread busyThread = new Thread(new BusyRunner(), \u0026#34;BusyThread\u0026#34;); busyThread.setDaemon(true); sleepThread.start(); busyThread.start(); // 休眠5秒，让sleepThread和busyThread充分运行 TimeUnit.SECONDS.sleep(5); sleepThread.interrupt(); busyThread.interrupt(); log.info(\u0026#34;SleepThread interrupted is {}\u0026#34;, sleepThread.isInterrupted()); log.info(\u0026#34;BusyThread interrupted is {}\u0026#34;, busyThread.isInterrupted()); // 防止sleepThread和busyThread立刻退出 TimeUnit.SECONDS.sleep(5); log.info(\u0026#34;exit\u0026#34;); } static class SleepRunner implements Runnable { @Override public void run() { try { while (true) { Thread.sleep(2000); } } catch (InterruptedException e) { log.error(\u0026#34;SleepThread interrupted is {}\u0026#34;, Thread.currentThread().isInterrupted()); Thread.currentThread().interrupt(); log.error(\u0026#34;SleepThread interrupted is {}\u0026#34;, Thread.currentThread().isInterrupted()); } log.info(\u0026#34;exit\u0026#34;); } } static class BusyRunner implements Runnable { @Override public void run() { if (1 == 1) { while (true) { } } log.info(\u0026#34;exit\u0026#34;); } } } // 打印：\n1 2 3 4 5 6 [14 10:20:55,269 INFO ] [main] Interrupted - SleepThread interrupted is false [14 10:20:55,269 ERROR] [SleepThread] Interrupted - SleepThread interrupted is false [14 10:20:55,270 INFO ] [main] Interrupted - BusyThread interrupted is true [14 10:20:55,270 ERROR] [SleepThread] Interrupted - SleepThread interrupted is true [14 10:20:55,271 INFO ] [SleepThread] Interrupted - exit [14 10:21:00,271 INFO ] [main] Interrupted - exit 从日志中可以看到：\n打断的确是一个标记，对于未处于可打断状态的线程，或者没有处理打断状态的线程是没有影响的，就像 BusyThread； 使用 interrupt 打断睡眠线程，也的确符合上面的情况，但是因为收到 InterruptedException 的时候会清楚中断标记，所以这里可以再次设置中断标记； 当然以上只是简单的举例，中断机制如何使用还是要根据具体的业务逻辑来确定；另外以上的实例代码是出自《Java 并发编程的艺术》，有兴趣的也可以找书来看一下；\n总结 以上的内容其主要目的是为了帮助你构建一个相对完善的线程知识体系，其中还有很多的细节没有讲到，具体内容还需要结合实际场景分析； ","date":"2021-03-27T00:00:00Z","permalink":"http://localhost:1313/p/thread%E8%AF%A6%E8%A7%A3/","title":"Thread详解"},{"content":"记录一个使用Java转图片的第三方工具\n1 2 3 4 5 6 \u0026lt;!-- https://mvnrepository.com/artifact/net.sf.cssbox/cssbox --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;net.sf.cssbox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cssbox\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 使用方法很简单，伪代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 ImageRenderer render = new ImageRenderer(); ByteArrayOutputStream os = new ByteArrayOutputStream(); //创建一个临时的HTML文件 Path tempFile = Files.createTempFile(IdWorker.getMillisecond(), \u0026#34;.html\u0026#34;); //将HTML字节流写入到临时文件中 Files.write(tempFile,createHtml()); render.renderURL(tempFile.toUri().toString(), os); String fileName = \u0026#34;test.png\u0026#34;; //将图片上传到OSS AliyunOSSUtil.upload(AliyunOSSUtil.toOSSFilePath(fileName, sysUser.tenantId()), new ByteArrayInputStream(os.toByteArray())); //删除临时文件 Files.deleteIfExists(tempFile); 我的方案是使用freemarker模板引擎先将数据渲染到成html文件，然后通过html文件生成一个图片，将图片上传到OSS中，最后删除临时生成的html文件。\n","date":"2021-03-25T00:00:00Z","permalink":"http://localhost:1313/p/java%E5%B0%86html%E8%BD%AC%E4%B8%BA%E5%9B%BE%E7%89%87/","title":"Java将HTML转为图片"},{"content":" 转载自: https://www.baeldung.com/java-string-constant-pool-heap-stack\n1.简介 每当我们声明一个变量或创建一个对象时，它就会存储在内存中。在较高的级别上，Java将内存分为两个块：stack和heap。两种存储器均存储特定类型的数据，并且具有不同的存储和访问模式。\n2.字符串常量池 该字符串常量池是一个特殊的存储区。**当我们声明String时，JVM在池中创建对象并将其引用存储在堆栈中。**在内存中创建每个String对象之前，JVM执行一些步骤来减少内存开销。\n字符串常量池在其实现中使用HashMap。HashMap的每个存储桶均包含具有相同哈希码的String列表。在Java的早期版本中，池的存储区域是固定大小的，并且通常会导致*“无法为对象堆保留足够的空间”* 错误。\n**当系统加载类时，所有类的*String*文字都将进入应用程序级池。**这是因为不同类的相等String文字必须是相同的Object。在这些情况下，池中的数据应可用于每个类而没有任何依赖关系。\n通常，堆栈存储短期的数据。它包括局部基本变量，堆对象的引用以及执行中的方法。堆允许动态分配内存，在运行时存储Java对象和JRE类。\n堆允许全局访问，并且在应用程序的生存期内，堆中的数据存储可用于所有线程，而堆栈上的数据存储具有私有作用域，只有所有者线程可以访问它们。\n堆栈将数据存储在连续的存储块中，并允许随机访问。如果类需要池中的随机String，则由于堆栈的LIFO（后进先出）规则，该类可能不可用。相反，堆会动态分配内存，并允许我们以任何方式访问数据。\n假设我们有一个由不同类型的变量组成的代码段。堆栈将存储int文字的值以及String和Demo对象的引用*。任何对象的值都将存储在堆中，所有String*文字都放入堆中的池中：\n线程完成执行后，将立即释放在堆栈上创建的变量。相反，垃圾收集器回收堆中的资源。同样，垃圾收集器从池中收集未引用的项目。\n**池的默认大小在不同平台上可能会有所不同。**无论如何，它仍然比可用堆栈大小大得多。在JDK 7之前，该池是permgen空间的一部分，从JDK 7到现在，它是主堆内存的一部分。\n3.结论 在这篇简短的文章中，我们了解了String常量池的存储区域。堆栈和堆具有不同的特性来存储和访问数据。从内存分配到其访问和可用性，堆是最适合存储String常量池的区域。\n实际上，池从未成为堆栈内存的一部分。\n","date":"2021-03-24T00:00:00Z","permalink":"http://localhost:1313/p/java%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0%E4%BD%8D%E4%BA%8E%E5%93%AA%E9%87%8C%E5%A0%86%E6%88%96%E5%A0%86%E6%A0%88/","title":"Java的字符串常量池位于哪里，堆或堆栈？"},{"content":"GitHub的一个学习路线仓库 https://github.com/kamranahmedse/developer-roadmap\n","date":"2021-03-24T00:00:00Z","permalink":"http://localhost:1313/p/%E5%90%8E%E7%AB%AF%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/","title":"后端学习路线"},{"content":" 转载自：https://www.cnblogs.com/dennyzhangdd/p/7218510.html\n一、论文简介 闲来无事，看看源码，发现了一篇JDK作者的论文《The java.util.concurrent Synchronizer Framework》主要描述了作者对 AbstractQueuedSynchronizer 同步器框架的设计和实现。权威性毋庸置疑！自然需要拜读一下，配上中文翻译，希望大家能有所收获。\n二、原文链接 论文英文版原文链接：http://gee.cs.oswego.edu/dl/papers/aqs.pdf\nhttp://gee.cs.oswego.edu/ 这个是老李头的主页，里面有他的部分贡献，感兴趣的可以关注一下，老李头确实比较厉害。\n三、中文翻译 摘要 在 J2SE 1.5 的 java.util.concurrent 包（下称 j.u.c 包）中，大部分的同步器（例如锁，屏障等等）都是基于 AbstractQueuedSynchronizer 类（下称 AQS 类），这个简单的框架而构建的。这个框架为同步状态的原子性管理、线程的阻塞和解除阻塞以及排队提供了一种通用的机制。这篇论文主要描述了这个框架基本原理、设计、实现、用法以及性能。\n1. 背景介绍 通过 JCP 的 JSR166 规范，Java 的 1.5 版本引入了 j.u.c 包，这个包提供了一系列支持中等程度并发的类。这些组件是一系列的同步器（抽象数据类型(ADT)）。这些同步器主要维护着以下几个功能：内部同步状态的管理(例如：表示一个锁的状态是获取还是释放)，同步状态的更新和检查操作，且至少有一个方法会导致调用线程在同步状态被获取时阻塞，以及在其他线程改变这个同步状态时解除线程的阻塞。上述的这些的实际例子包括：互斥排它锁的不同形式、读写锁、信号量、屏障、Future、事件指示器以及传送队列等。\n几乎任一同步器都可以用来实现其他形式的同步器。例如，可以用可重入锁实现信号量或者用信号量实现可重入锁。但是，这样做带来的复杂性，开销，不灵活使其至多只能是个二流工程，且缺乏吸引力。如果任何这样的构造方式不能在本质上比其他形式更简洁，那么开发者就不应该随意地选择其中的某个来构建另一个同步器。取而代之，JSR166 建立了一个小框架，AQS 类。这个框架为构造同步器提供一种通用的机制，并且被 j.u.c 包中大部分类使用，同时很多用户也用它来定义自己的同步器。\n在这篇论文的下面部分会讨论这个框架的需求、设计与实现背后的主要思路、示例用法，以及性能指标的一些测量。\n2 需求 2.1 功能 同步器一般包含两种方法，一种是 acquire，另一种是 release。acquire 操作阻塞调用的线程，直到或除非同步状态允许其继续执行。而 release 操作则是通过某种方式改变同步状态，使得一或多个被 acquire 阻塞的线程继续执行。\nj.u.c 包中并没有对同步器的API做一个统一的定义。因此，有一些类定义了通用的接口（如 Lock），而另外一些则定义了其专有的版本。因此在不同的类中，acquire 和 release 操作的名字和形式会各有不同。例如：Lock.lock，Semaphore.acquire，CountDownLatch.await 和 FutureTask.get，在这个框架里，这些方法都是 acquire 操作。但是，J.U.C 为支持一系列常见的使用选项，在类间都有个一致约定。在有意义的情况下，每一个同步器都支持下面的操作：\n阻塞和非阻塞（例如 tryLock）同步 可选的超时设置，让调用者可以放弃等待 通过中断实现的任务取消，通常是分为两个版本，一个 acquire 可取消，而另一个不可以 同步器的实现根据其状态是否独占而有所不同。独占状态的同步器，在同一时间只有一个线程可以通过阻塞点，而共享状态的同步器可以同时有多个线程在执行。一般锁的实现类往往只维护独占状态，但是，例如计数信号量在数量许可的情况下，允许多个线程同时执行。为了使框架能得到广泛应用，这两种模式都要支持。\nj.u.c 包里还定义了 Condition 接口，用于支持监控形式的 await/signal 操作，这些操作与独占模式的 Lock 类有关，且 Condition 的实现天生就和与其关联的 Lock 类紧密相关。\n2.2 性能目标 Java 内置锁（使用 synchronized 的方法或代码块）的性能问题一直以来都在被人们关注，并且已经有一系列的文章描述其构造（例如引文 [^1],[^3]）。然而，大部分的研究主要关注的是在单核处理器上大部分时候使用于单线程上下文环境中时，如何尽量降低其空间（因为任何的 Java 对象都可以当成是锁）和时间的开销。对于同步器来说这些都不是特别重要：程序员仅在需要的时候才会使用同步器，因此并不需要压缩空间来避免浪费，并且同步器几乎是专门用在多线程设计中（特别是在多核处理器上），在这种环境下，偶尔的竞争是在意料之中的。因此，常规的 JVM 锁优化策略主要是针对零竞争的场景，而其它场景则使用缺乏可预见性的“慢速路径（slow paths）” ，所以常规的JVM锁优化策略并不适用于严重依赖于 J.U.C 包的典型多线程服务端应用。\n这里主要的性能目标是可伸缩性，即在大部分情况下，即使，或特别在同步器有竞争的情况下，稳定地保证其效率。在理想的情况下，不管有多少线程正试图通过同步点，通过同步点的开销都应该是个常量。在某一线程被允许通过同步点但还没有通过的情况下，使其耗费的总时间最少，这是主要目标之一。然而，这也必须考虑平衡各种资源，包括总 CPU 时间的需求，内存负载以及线程调度的开销。例如：获取自旋锁通常比阻塞锁所需的时间更短，但是通常也会浪费 CPU 时钟周期，并且造成内存竞争，所以使用的并不频繁。\n实现同步器的这些目标包含了两种不同的使用类型。大部分应用程序是最大化其总的吞吐量，容错性，并且最好保证尽量减少饥饿的情况。然而，对于那些控制资源分配的程序来说，更重要是去维持多线程读取的公平性，可以接受较差的总吞吐量。没有任何框架可以代表用户去决定应该选择哪一个方式，因此，应该提供不同的公平策略。\n无论同步器的内部实现是多么的精雕细琢，它还是会在某些应用中产生性能瓶颈。因此，框架必须提供相应的监视工具让用户发现和缓和这些瓶颈。至少需要提供一种方式来确定有多少线程被阻塞了。\n3 设计与实现 同步器背后的基本思想非常简单。acquire 操作如下：\n1 2 3 4 5 while (synchronization state does not allow acquire) { enqueue current thread if not already queued; possibly block current thread; } dequeue current thread if it was queued; release 操作如下：\n1 2 3 update synchronization state; if (state may permit a blocked thread to acquire) unblock one or more queued threads; 为了实现上述操作，需要下面三个基本组件的相互协作：\n同步状态的原子性管理 线程的阻塞与解除阻塞 队列的管理 创建一个框架分别实现这三个组件是有可能的。但是，这会让整个框架既难用又没效率。例如：存储在队列节点的信息必须与解除阻塞所需要的信息一致，而暴露出的方法的签名必须依赖于同步状态的特性。\n同步器框架的核心决策是为这三个组件选择一个具体实现，同时在使用方式上又有大量选项可用。这里有意地限制了其适用范围，但是提供了足够的效率，使得实际上没有理由在合适的情况下不用这个框架而去重新建造一个。\n3.1 同步状态 AQS 类使用单个 int（32位）来保存同步状态，并暴露出 getState、setState 以及 compareAndSet 操作来读取和更新这个状态。这些方法都依赖于 j.u.c atomic 包的支持，这个包提供了兼容 JSR133 中 volatile 在读和写上的语义，并且通过使用本地的 compare-and-swap 或 load-linked/store-conditional 指令来实现 compareAndSetState，使得仅当同步状态拥有一个期望值的时候，才会被原子地设置成新值。\n将同步状态限制为一个 32 位的整形是出于实践上的考量。虽然 JSR166 也提供了 64 位 long 字段的原子性操作，但这些操作在很多平台上还是使用内部锁的方式来模拟实现的，这会使同步器的性能可能不会很理想。当然，将来可能会有一个类是专门使用 64 位的状态的。然而现在就引入这么一个类到这个包里并不是一个很好的决定（译者注：JDK1.6 中已经包含 java.util.concurrent.locks.AbstractQueuedLongSynchronizer 类，即使用 long 形式维护同步状态的一个 AbstractQueuedSynchronizer 版本）。目前来说，32 位的状态对大多数应用程序都是足够的。在 j.u.c 包中，只有一个同步器类可能需要多于 32 位来维持状态，那就是 CyclicBarrier 类，所以，它用了锁（该包中大多数更高层次的工具亦是如此）。\n基于 AQS 的具体实现类必须根据暴露出的状态相关的方法定义 tryAcquire 和 tryRelease 方法，以控制 acquire 和 release 操作。当同步状态满足时，tryAcquire 方法必须返回 true，而当新的同步状态允许后续 acquire 时，tryRelease 方法也必须返回 true。这些方法都接受一个 int 类型的参数用于传递想要的状态。例如：可重入锁中，当某个线程从条件等待中返回，然后重新获取锁时，为了重新建立循环计数的场景。很多同步器并不需要这样一个参数，因此忽略它即可。\n3.2 阻塞 在 JSR166 之前，阻塞线程和解除线程阻塞都是基于 Java 内置监视器，没有基于 Java API 可以用来创建同步器。唯一可以选择的是 Thread.suspend 和 Thread.resume，但是它们都有无法解决的竞态问题，所以也没法用：当一个非阻塞的线程在一个正准备阻塞的线程调用 suspend 前调用了 resume，这个 resume 操作将不会有什么效果。\nj.u.c 包有一个 LockSuport 类，这个类中包含了解决这个问题的方法。方法 LockSupport.park 阻塞当前线程除非/直到有个 LockSupport.unpark 方法被调用（unpark 方法被提前调用也是可以的）。unpark的调用是没有被计数的，因此在一个park调用前多次调用 unpark 方法只会解除一个 park 操作。另外，它们作用于每个线程而不是每个同步器。一个线程在一个新的同步器上调用 park 操作可能会立即返回，因为在此之前可能有 “剩余的” unpark 操作。但是，在缺少一个 unpark 操作时，下一次调用 park 就会阻塞。虽然可以显式地消除这个状态（译者注：就是多余的 unpark 调用），但并不值得这样做。在需要的时候多次调用 park 会更高效。\n这个简单的机制与有些用法在某种程度上是相似的，例如 Solaris-9 的线程库，WIN32 中的“可消费事件”，以及 Linux 中的 NPTL 线程库。因此最常见的运行 Java 的平台上都有相对应的有效实现。（但目前 Solaris 和 Linux 上的 Sun Hotspot JVM 参考实现实际上是使用一个 pthread 的 condvar 来适应目前的运行时设计的）。park 方法同样支持可选的相对或绝对的超时设置，以及与 JVM 的 Thread.interrupt 结合 —— 可通过中断来 unpark 一个线程。\n3.3 队列 整个框架的关键就是如何管理被阻塞的线程的队列，该队列是严格的 FIFO 队列，因此，框架不支持基于优先级的同步。\n同步队列的最佳选择是自身没有使用底层锁来构造的非阻塞数据结构，目前，业界对此很少有争议。而其中主要有两个选择：一个是 Mellor-Crummey 和 Scott 锁（MCS锁）[^9] 的变体，另一个是 Craig，Landin 和Hagersten 锁（CLH锁）[^5][^8][^10] 的变体。一直以来，CLH 锁仅被用于自旋锁。但是，在这个框架中，CLH 锁显然比 MCS 锁更合适。因为CLH锁可以更容易地去实现 “取消（cancellation）” 和 “超时” 功能，因此我们选择了 CLH 锁作为实现的基础。但是最终的设计已经与原来的 CLH 锁有较大的出入，因此下文将对此做出解释。\nCLH 队列实际上并不那么像队列，因为它的入队和出队操作都与它的用途（即用作锁）紧密相关。它是一个链表队列，通过两个字段 head 和 tail 来存取，这两个字段是可原子更新的，两者在初始化时都指向了一个空节点。\n一个新的节点 node 通过一个原子操作入队：\n1 2 3 do { pred = tail; } while(!tail.compareAndSet(pred, node)); 每一个节点的 “释放” 状态都保存在其前驱节点中。因此，自旋锁的 “自旋” 操作就如下：\n1 while (pred.status != RELEASED); // spin 自旋后的出队操作只需将 head 字段指向刚刚得到锁的节点：\n1 head = node; CLH 锁的优点在于其入队和出队操作是快速、无锁的，以及无障碍的（即使在竞争下，某个线程总会赢得一次插入机会而能继续执行）；且探测是否有线程正在等待也很快（只要测试一下 head 是否与 tail 相等）；同时，“释放” 状态是分散的（译者注：几乎每个节点都保存了这个状态，当前节点保存了其后驱节点的 “释放” 状态，因此它们是分散的，不是集中于一块的。），避免了一些不必要的内存竞争。\n在原始版本的 CLH 锁中，节点间甚至都没有互相链接。自旋锁中，pred 变量可以是一个局部变量。然而，Scott 和 Scherer 证明了通过在节点中显式地维护前驱节点，CLH 锁就可以处理 “超时” 和各种形式的 “取消”：如果一个节点的前驱节点取消了，这个节点就可以滑动去使用前面一个节点的状态字段。\n为了将 CLH 队列用于阻塞式同步器，需要做些额外的修改以提供一种高效的方式定位某个节点的后继节点。在自旋锁中，一个节点只需要改变其状态，下一次自旋中其后继节点就能注意到这个改变，所以节点间的链接并不是必须的。但在阻塞式同步器中，一个节点需要显式地唤醒（unpark）其后继节点。\nAQS 队列的节点包含一个 next 链接到它的后继节点。但是，由于没有针对双向链表节点的类似compareAndSet 的原子性无锁插入指令，因此这个next链接的设置并非作为原子性插入操作的一部分，而仅是在节点被插入后简单地赋值：\n1 pred.next = node; next 链接仅是一种优化。如果通过某个节点的 next 字段发现其后继结点不存在（或看似被取消了），总是可以使用 pred 字段从尾部开始向前遍历来检查是否真的有后续节点。\n第二个对 CLH 队列主要的修改是将每个节点都有的状态字段用于控制阻塞而非自旋。在同步器框架中，仅在线程调用具体子类中的 tryAcquire 方法返回 true 时，队列中的线程才能从 acquire 操作中返回；而单个 “released” 位是不够的。但仍然需要做些控制以确保当一个活动的线程位于队列头部时，仅允许其调用 tryAcquire；这时的 acquire 可能会失败，然后（重新）阻塞。这种情况不需要读取状态标识，因为可以通过检查当前节点的前驱是否为head来确定权限。与自旋锁不同，读取 head 以保证复制时不会有太多的内存竞争（there is not enough memory contention reading head to warrant replication.）。然而，“取消” 状态必须存在于状态字段中。\n队列节点的状态字段也用于避免没有必要的 park 和 unpark 调用。虽然这些方法跟阻塞原语一样快，但在跨越 Java 和 JVM runtime 以及操作系统边界时仍有可避免的开销。在调用 park 前，线程设置一个“唤醒（signal me）”位，然后再一次检查同步和节点状态。一个释放的线程会清空其自身状态。这样线程就不必频繁地尝试阻塞，特别是在锁相关的类中，这样会浪费时间等待下一个符合条件的线程去申请锁，从而加剧其它竞争的影响。除非后继节点设置了“唤醒”位（译者注：源码中为-1），否则这也可避免正在release的线程去判断其后继节点。这反过来也消除了这些情形：除非“唤醒”与“取消”同时发生，否则必须遍历多个节点来处理一个似乎为null的next字段。\n同步框架中使用的 CLH 锁的变体与其他语言中的相比，主要区别可能是同步框架中使用的 CLH 锁需要依赖垃圾回收管理节点的内存，这就避免了一些复杂性和开销。但是，即使依赖 GC 也仍然需要在确定链接字段不再需要时将其置为 null。这往往可以与出队操作一起完成。否则，无用的节点仍然可触及，它们就没法被回收。\n其它一些更深入的微调，包括 CLH 队列首次遇到竞争时才需要的初始空节点的延迟初始化等，都可以在J2SE1.5的版本的源代码文档中找到相应的描述。\n抛开这些细节，基本的 acquire 操作的最终实现的一般形式如下（互斥，非中断，无超时）：\n1 2 3 4 5 6 7 8 9 10 11 12 if(!tryAcquire(arg)) { node = create and enqueue new node; pred = node\u0026#39;s effective predecessor; while (pred is not head node || !tryAcquire(arg)) { if (pred\u0026#39;s signal bit is set) pard() else compareAndSet pred\u0026#39;s signal bit to true; pred = node\u0026#39;s effective predecessor; } head = node; } release操作：\n1 2 3 4 if(tryRelease(arg) \u0026amp;\u0026amp; head node\u0026#39;s signal bit is set) { compareAndSet head\u0026#39;s bit to false; unpark head\u0026#39;s successor, if one exist } acquire 操作的主循环次数依赖于具体实现类中 tryAcquire 的实现方式。另一方面，在没有 “取消” 操作的情况下，每一个组件的 acquire 和 release 都是一个 O(1) 的操作，忽略 park 中发生的所有操作系统线程调度。\n支持 “取消” 操作主要是要在 acquire 循环里的 park 返回时检查中断或超时。由超时或中断而被取消等待的线程会设置其节点状态，然后unpark其后继节点。在有 “取消” 的情况下，判断其前驱节点和后继节点以及重置状态可能需要 O(n) 的遍历（n 是队列的长度）。由于 “取消” 操作，该线程再也不会被阻塞，节点的链接和状态字段可以被快速重建。\n3.4 条件队列 AQS 框架提供了一个 ConditionObject 类，给维护独占同步的类以及实现 Lock 接口的类使用。一个锁对象可以关联任意数目的条件对象，可以提供典型的管程风格的 await、signal 和 signalAll 操作，包括带有超时的，以及一些检测、监控的方法。\n通过修正一些设计决策，ConditionObject 类有效地将条件（conditions）与其它同步操作结合到了一起。该类只支持 Java 风格的管程访问规则，这些规则中，仅当当前线程持有锁且要操作的条件（condition）属于该锁时，条件操作才是合法的（一些替代操作的讨论参考 [^4]）。这样，一个 ConditionObject 关联到一个 ReentrantLock 上就表现的跟内置的管程（通过 Object.wait 等）一样了。两者的不同仅仅在于方法的名称、额外的功能以及用户可以为每个锁声明多个条件。\nConditionObject 使用了与同步器一样的内部队列节点。但是，是在一个单独的条件队列中维护这些节点的。signal 操作是通过将节点从条件队列转移到锁队列中来实现的，而没有必要在需要唤醒的线程重新获取到锁之前将其唤醒。\n基本的 await 操作如下：\n1 2 3 4 create and add new node to conditon queue; release lock; block until node is on lock queue; re-acquire lock; signal操作如下：\n1 transfer the first node from condition queue to lock queue; 因为只有在持有锁的时候才能执行这些操作，因此他们可以使用顺序链表队列操作来维护条件队列（在节点中用一个 nextWaiter 字段）。转移操作仅仅把第一个节点从条件队列中的链接解除，然后通过 CLH 插入操作将其插入到锁队列上。\n实现这些操作主要复杂在，因超时或 Thread.interrupt 导致取消了条件等待时，该如何处理。“取消” 和 “唤醒” 几乎同时发生就会有竞态问题，最终的结果遵照内置管程相关的规范。JSR133 修订以后，就要求如果中断发生在 signal 操作之前，await 方法必须在重新获取到锁后，抛出 InterruptedException。但是，如果中断发生在 signal 后，await 必须返回且不抛异常，同时设置线程的中断状态。\n为了维护适当的顺序，队列节点状态变量中的一个位记录了该节点是否已经（或正在）被转移。“唤醒” 和 “取消” 相关的代码都会尝试用 compareAndSet 修改这个状态。如果某次 signal 操作修改失败，就会转移队列中的下一个节点（如果存在的话）。如果某次 “取消” 操作修改失败，就必须中止此次转移，然后等待重新获得锁。后面的情况采用了一个潜在的无限的自旋等待。在节点成功的被插到锁队列之前，被 “取消” 的等待不能重新获得锁，所以必须自旋等待 CLH 队列插入（即 compareAndSet 操作）被 “唤醒” 线程成功执行。这里极少需要自旋，且自旋里使用 Thread.yield 来提示应该调度某一其它线程，理想情况下就是执行 signal 的那个线程。虽然有可能在这里为 “取消” 实现一个帮助策略以帮助插入节点，但这种情况实在太少，找不到合适的理由来增加这些开销。在其它所有的情况下，这个基本的机制都不需要自旋或 yield，因此在单处理器上保持着合理的性能。\n4 用法 AQS 类将上述的功能结合到一起，并且作为一种基于 “模版方法模式” [^6] 的基类提供给同步器。子类只需定义状态的检查与更新相关的方法，这些方法控制着 acquire 和 release 操作。然而，将 AQS 的子类作为同步器 ADT 并不适合，因为这个类必须提供方法在内部控制 acquire 和 release 的规则，这些都不应该被用户所看到。所有 java.util.concurrent 包中的同步器类都声明了一个私有的继承了 AbstractQueuedSynchronizer 的内部类，并且把所有同步方法都委托给这个内部类。这样各个同步器类的公开方法就可以使用适合自己的名称。\n下面是一个最简单的 Mutex 类的实现，它使用同步状态 0 表示解锁，1 表示锁定。这个类并不需要同步方法中的参数，因此这里在调用的时候使用 0 作为实参，方法实现里将其忽略。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Mutex { class Sync extends AbstractQueuedSynchronizer { public boolean tryAcquire(int ignore) { return compareAndSetState(0, 1); } public boolean tryRelease(int ignore) { setState(0); return true; } } private final Sync sync = new Sync(); public void lock() { sync.acquire(0); } public void unlock() { sync.release(0); } } 这个例子的一个更完整的版本，以及其它用法指南，可以在J2SE的文档中找到。还可以有一些变体。如，tryAcquire 可以使用一种 “test-and-test-and-set” 策略，即在改变状态值前先对状态进行校验。\n令人诧异的是，像互斥锁这样性能敏感的东西也打算通过委托和虚方法结合的方式来定义。然而，这正是现代动态编译器一直在重点研究的面向对象设计结构。编译器擅长将这方面的开销优化掉，起码会优化频繁调用同步器的那些代码。\nAbstractQueuedSynchronizer 类也提供了一些方法用来协助策略控制。例如，基础的 acquire 方法有可超时和可中断的版本。虽然到目前为止，我们的讨论都集中在像锁这样的独占模式的同步器上，但AbstractQueuedSynchronizer 类也包含另一组方法（如 acquireShared），它们的不同点在于 tryAcquireShared 和 tryReleaseShared 方法能够告知框架（通过它们的返回值）尚能接受更多的请求，最终框架会通过级联的 signal(cascading signals) 唤醒多个线程。\n虽然将同步器序列化（持久化存储或传输）一般来说没有太大意义，但这些类经常会被用于构造其它类，例如线程安全的集合，而这些集合通常是可序列化的。AbstractQueuedSynchronizer 和 ConditionObject 类都提供了方法用于序列化同步状态，但不会序列化潜在的被阻塞的线程，也不会序列化其它内部暂时性的簿记（bookkeeping）变量。即使如此，在反序列化时，大部分同步器类也只仅将同步状态重置为初始值，这与内置锁的隐式策略一致 —— 总是反序列化到一个解锁状态。这相当于一个空操作，但仍必须显式地支持以便final字段能够反序列化。\n4.1 公平调度的控制 尽管同步器是基于 FIFO 队列的，但它们并不一定就得是公平的。可以注意到，在基础的 acquire 算法（3.3节）中，tryAcquire 是在入队前被执行的。因此一个新的 acquire 线程能够“窃取”本该属于队列头部第一个线程通过同步器的机会。\n可闯入的 FIFO 策略通常会提供比其它技术更高的总吞吐率。当一个有竞争的锁已经空闲，而下一个准备获取锁的线程又正在解除阻塞的过程中，这时就没有线程可以获取到这个锁，如果使用闯入策略，则可减少这之间的时间间隔。与此同时，这种策略还可避免过分的，无效率的竞争，这种竞争是由于只允许一个（第一个）排队的线程被唤醒然后尝试 acquire 操作导致的。在只要求短时间持有同步器的场景中，创建同步器的开发者可以通过定义 tryAcquire 在控制权返回之前重复调用自己若干次，来进一步凸显闯入的效果。\n可闯入的 FIFO 同步器只有概率性的公平属性。锁队列头部一个解除了阻塞的线程拥有一次无偏向的机会（译者注：即不会偏向队头的线程也不会偏向闯入的线程）来赢得与闯入的线程之间的竞争，如果竞争失败，要么重新阻塞要么进行重试。然而，如果闯入的线程到达的速度比队头的线程解除阻塞快，那么在队列中的第一个线程将很难赢得竞争，以至于几乎总要重新阻塞，并且它的后继节点也会一直保持阻塞。对于短暂持有的同步器来说，在队列中第一个线程被解除阻塞期间，多处理器上很可能发生过多次闯入（译者注：即闯入的线程的 acquire 操作）和 release 了。正如下文所提到的，最终结果就是保持一或多个线程的高进展速度的同时，仍至少在一定概率上避免了饥饿的发生。\n当有更高的公平性需求时，实现起来也很简单。如果需要严格的公平性，程序员可以把 tryAcquire 方法定义为，若当前线程不是队列的头节点（可通过 getFirstQueuedThread 方法检查，这是框架提供的为数不多的几个检测方法之一），则立即失败（返回false）。\n一个更快，但非严格公平的变体可以这样做，若队列为空（判断的瞬间），仍然允许 tryAcquire 执行成功。在这种情况下，多个线程同时遇到一个空队列时可能会去竞争以使自己第一个获得锁，这样，通常至少有一个线程是无需入队列的。java.util.concurrent 包中所有支持公平模式的同步器都采用了这种策略。\n尽管公平性设置在实践中很有用，但是它们并没有保障，因为 Java Language Specification 没有提供这样的调度保证。例如：即使是严格公平的同步器，如果一组线程永远不需要阻塞来达到互相等待，那么 JVM 可能会决定纯粹以顺序方式运行它们。在实际中，单处理器上，在抢占式上下文切换之前，这样的线程有可能是各自运行了一段时间。如果这样一个线程正持有某个互斥锁，它将很快会被切换回来，仅是为了释放其持有的锁，然后会继续阻塞，因为它知道有另外一个线程需要这把锁，这更增加了同步器可用但没有线程能来获取之间的间隔。同步器公平性设置在多处理器上的影响可能会更大，因为在这种环境下会产生更多的交错，因此一个线程就会有更多的机会发现锁被另一个线程请求。\n在高竞争下，当保护的是短暂持有锁的代码体时，尽管性能可能会较差，但公平锁仍然能有效地工作。例如，当公平性锁保护的是相对长的代码体和/或有着相对长的锁间(inter-lock)间隔，在这种情况下，闯入只能带来很小的性能优势，但却可能会大大增加无限等待的风险。同步器框架将这些工程决策留给用户来确定。\n4.2 同步器 下面是 java.util.concurrent 包中同步器定义方式的概述：\nReentrantLock 类使用 AQS 同步状态来保存锁（重复）持有的次数。当锁被一个线程获取时，ReentrantLock 也会记录下当前获得锁的线程标识，以便检查是否是重复获取，以及当错误的线程（译者注：如果线程不是锁的持有者，在此线程中执行该锁的 unlock 操作就是非法的）试图进行解锁操作时检测是否存在非法状态异常。ReentrantLock 也使用了 AQS 提供的 ConditionObject，还向外暴露了其它监控和监测相关的方法。ReentrantLock 通过在内部声明两个不同的 AbstractQueuedSynchronizer 实现类（提供公平模式的那个禁用了闯入策略）来实现可选的公平模式，在创建 ReentrantLock 实例的时候根据设置（译者注：即 ReentrantLock 构造方法中的 fair 参数）使用相应的 AbstractQueuedSynchronizer 实现类。\nReentrantReadWriteLock 类使用 AQS 同步状态中的 16 位来保存写锁持有的次数，剩下的 16 位用来保存读锁的持有次数。WriteLock 的构建方式同 ReentrantLock。ReadLock 则通过使用 acquireShared 方法来支持同时允许多个读线程。\nSemaphore 类（计数信号量）使用 AQS 同步状态来保存信号量的当前计数。它里面定义的 acquireShared 方法会减少计数，或当计数为非正值时阻塞线程；tryRelease 方法会增加计数，可能在计数为正值时还要解除线程的阻塞。\nCountDownLatch 类使用 AQS 同步状态来表示计数。当该计数为 0 时，所有的 acquire 操作（译者注：acquire 操作是从 aqs 的角度说的，对应到 CountDownLatch 中就是 await 方法）才能通过。\nFutureTask 类使用 AQS 同步状态来表示某个异步计算任务的运行状态（初始化、运行中、被取消和完成）。设置（译者注：FutureTask 的 set 方法）或取消（译者注：FutureTask 的 cancel 方法）一个 FutureTask 时会调用 AQS 的 release 操作，等待计算结果的线程的阻塞解除是通过 AQS 的 acquire 操作实现的。\nSynchronousQueues 类（一种 CSP（Communicating Sequential Processes）形式的传递）使用了内部的等待节点，这些节点可以用于协调生产者和消费者。同时，它使用 AQS 同步状态来控制当某个消费者消费当前一项时，允许一个生产者继续生产，反之亦然。\njava.util.concurrent 包的使用者当然也可以为自定义的应用定义自己的同步器。例如，那些曾考虑到过的，但没有采纳进这个包的同步器包括提供WIN32事件各种风格的语义类，二元信号量，集中管理的锁以及基于树的屏障。\n5 性能 虽然 AQS 框架除了支持互斥锁外，还支持其它形式的同步方式，但锁的性能是最容易测量和比较的。即使如此，也还存在许多不同的测量方式。这里的实验主要是设计来展示锁的开销和吞吐量。\n在每个测试中，所有线程都重复的更新一个伪随机数，该随机数由 nextRandom(int seed) 方法计算：\n1 2 int t = (seed % 127773) * 16807 - (seed / 127773) * 2836; return (t \u0026gt; 0) ? t : t + 0x7fffffff; 在每次迭代中，线程以概率S在一个互斥锁下更新共享的生成器，否则（译者注：概率为 1-S）更新其自己局部的生成器，此时是不需要锁的。如此，锁占用区域的耗时是短暂的，这就使线程持有锁期间被抢占时的外界干扰降到了最小。这个函数的随机性主要是为了两个目的：确定是否需要使用锁（这个生成器足以应付这里的需求），以及使循环中的代码不可能被轻易地优化掉。\n这里比较了四种锁：内置锁，用的是 synchronized 块；互斥锁，用的是像第四节例子中的那样简单的 Mutex 类；可重入锁，用的是 ReentrantLock；以及公平锁，用的是 ReentrantLock 的公平模式。所有测试都运行在 J2SE1.5 JDK build46（大致与 beta2 相同）的 server 模式下。在收集测试数据前，测试程序先运行 20 次非竞争的测试，以排除 JVM “预热”（译者注：更多关于 “预热” 的内容，参见：Java 理论与实践: 动态编译与性能测量）过程的影响。除了公平模式下的测试只跑了一百万次迭代，其它每个线程中的测试都运行了一千万次迭代。\n该测试运行在四个 x86 机器和四个 UltraSparc 机器上。所有 x86 机器都运行的是 RedHat 基于 NPTL 2.4 内核和库的 Linux 系统。所有的 UltraSparc 机器都运行的是 Solaris-9。测试时所有系统的负载都很轻。根据该测试的特征，并不要求系统完全空闲（译者注：即测试时操作系统上有其它较轻的负载也不会影响本次测试的结果。）。“4P” 这个名字反映出双核超线程的Xeon更像是4路机器，而不是2路机器。这里没有将测试数据规范化。如下所示，同步的相对开销与处理器的数量、类型、速度之间不具备简单的关系。\n名字 处理器数量 类型 速度(Mhz) 1P 1 Pentium3 900 2P 2 Pentium3 1400 2A 2 Athlon 2000 4P 2HT Pentium4/Xeon 2400 1U 1 UltraSparc2 650 4U 4 UltraSparc2 450 8U 8 UltraSparc3 750 24U 24 UltraSparc3 750 表1 测试的平台\n5.1 开销 无竞争情况下的开销是通过仅运行一个线程，将概率 S 为 1 时的每次迭代时间减去概率 S 为 0（访问共享内存的概率为 0）时的每次迭代时间得到的（译者注：这里的“概率S”即前文提到的 “概率 S”，概率为 0 时是没有锁操作的，概率为 1 时是每次都有锁操作，因此将概率为1时的耗时减去概率为 0 时的耗时就是整个锁操作的开销。）。表 2 以纳秒为单位显示了非竞争场景下每次锁操作的开销。Mutex 类最接近于框架的基本耗时，可重入锁的额外开销是记录当前所有者线程和错误检查的耗时，对于公平锁来说还包含开始时检查队列是否为空的耗时。\n表格 2 也展示与内置锁的 “快速路径（fast path）” 对比，tryAcquire 的耗时。这里的差异主要反映出了各锁和机器中使用的不同的原子指令以及内存屏障的耗时。在多处理器上，这些指令常常是完全优于所有其它指令的。内置锁和同步器类之间的主要差别，显然是由于 Hotspot 锁在锁定和解锁时都使用了一次compareAndSet，而同步器的 acquire 操作使用了一次 compareAndSet ，但 release 操作用的是一次volatile写（即，多处理器上的一次内存屏障以及所有处理器上的重排序限制）。每个锁的绝对的和相对耗时因机器的不同而不同。\n机器 内置 互斥 可重入 公平可重入 1P 18 9 31 37 2P 58 71 77 81 2A 13 21 31 30 4P 116 95 109 117 1U 90 40 58 67 4U 122 82 100 115 8U 160 83 103 123 24U 161 84 108 119 表2 无竞争时的单锁开销（单位：纳秒）\n从另一个极端看，表 3 展示了概率 S 为 1，运行 256 个并发线程时产生了大规模的锁竞争下每个锁的开销。在完全饱和的情况下，可闯入的FIFO锁比内置锁的开销少了一个数量级（也就是更大的吞吐量），比公平锁更是少了两个数量级。这表现出即使有着极大的竞争，在维持线程进展方面可闯入FIFO策略的效率。\n表3也说明了即使在内部开销比较低的情况下，公平锁的性能也完全是由上下文切换的时间所决定的。列出的时间大致上都与各平台上线程阻塞和解除线程阻塞的时间相称。\n此外，后面增加的一个实验（仅使用机器 4P）表明，对于这里用到的短暂持有的锁，公平参数的设置在总差异中的影响很小。这里将线程终止时间间的差异记录成一个粗粒度的离散量数。在 4P 的机器上，公平锁的时间度量的标准差平均为 0.7%，可重入锁平均为 6.0%。作为对比，为模拟一个长时间持有锁的场景，测试中使每个线程在持有锁的情况下计算了16K次随机数。这时，总运行时间几乎是相同的（公平锁：9.79s，可重入锁：9.72s）。公平模式下的差异依然很小，标准差平均为 0.1%，而可重入锁上升到了平均 29.5%。\n| 机器 | 内置 | 互斥 | 可重入 | 公平可重入 | | 1P | 521 | 46 | 67 | 8327 | | 2P | 930 | 108 | 132 | 14967 | | 2A | 748 | 79 | 84 | 33910 | | 4P | 1146 | 188 | 247 | 15328 | | 1U | 879 | 153 | 177 | 41394 | | 4U | 2590 | 347 | 368 | 30004 | | 8U | 1274 | 157 | 174 | 31084 | | 24U | 1983 | 160 | 182 | 32291 |\n表格3 饱和时的单锁开销（单位：纳秒）\n5.2 吞吐量 大部分同步器都是用于无竞争和极大竞争之间的。这可以用实验在两个方面进行检查，通过修改固定个线程的竞争概率，和/或通过往拥有固定竞争概率的线程集合里增加更多的线程。为了说明这些影响，测试运行在不同的竞争概率和不同的线程数目下，都用的是可重入锁。附图使用了一个 slowdown 度量标准。\n这里，t是总运行时间，b是一个线程在没有竞争或同步下的基线时间，n 是线程数，p 是处理器数，S 是共享访问的比例（译者注：即前面的竞争概率 S）。计算结果是实际执行时间与理想执行时间（通常是无法得到的）的比率，理想执行时间是通过使用 Amdahl’s 法则计算出来的。理想时间模拟了一次没有同步开销，没有因锁争用而导致线程阻塞的执行过程。即使这样，在很低的竞争下，相比理想时间，有一些测试结果却表现出了很小的速度增长，大概是由于基线和测试之间的优化、流水线等方面有着轻微的差别。\n图中用以 2 为底的对数为比例进行了缩放。例如，值为 1 表示实际时间是理想时间的两倍，4 表示慢 16 倍。使用对数就不需要依赖一个随意的基线时间（这里指的是计算随机数的时间），因此，基于不同底数计算的结果表现出的趋势应该是类似的。这些测试使用的竞争概率从 1/128（标识为 “0.008”）到 1，以 2 的幂为步长，线程的数量从 1 到 1024，以 2 的幂的一半为步长。\n在单处理器（1P 和 1U）上，性能随着竞争的上升而下降，但不会随着线程数的增加而下降。多处理器在遭遇竞争时，性能下降的更快。根据多处理器相关的图表显示，开始出现的峰值处虽然只有几个线程的竞争，但相对性能通常却最差。这反映出了一个性能的过渡区域，在这里闯入的线程和被唤醒的线程都准备获取锁，这会让它们频繁的迫使对方阻塞。在大部分时候，过渡区域后面会紧接着一个平滑区域，因为此时几乎没有空闲的锁，所以会与单处理器上顺序执行的模式差不多；在多处理器机器上会较早进入平滑区域。例如，请注意，在满竞争（标识为“1.000”）下这些值表示，在处理器越少的机器上，会有更糟糕的相对速度下降。\n根据这些结果，可以针对阻塞（park/unpark）做进一步调优以减少上下文切换和相关的开销，这会给本框架带来小但显著的提升。此外，在多处理器上为短时间持有的但高竞争的锁采用某种形式的适应性自旋，可以避免这里看到的一些波动，这对同步器类大有裨益。虽然在跨不同上下文时适应性自旋很难很好的工作，但可以使用本框架为遇到这类使用配置的特定应用构建一个自定义形式的锁。\n6 总结 本文撰写之时，java.util.concurrent 包中的同步器框架还太新所以还不能在实践中使用。因此在 J2SE 1.5 最终版本发布之前都很难看到其大范围的使用，并且，它的设计，API 实现以及性能肯定还有无法预料的后果。但是，此时，这个框架明显能胜任其基本的目标，即为创建新的同步器提供一个高效的基础。\n7 致谢 Thanks to Dave Dice for countless ideas and advice during the development of this framework, to Mark Moir and Michael Scott for urging consideration of CLH queues, to David Holmes for critiquing early versions of the code and API, to Victor Luchangco and Bill Scherer for reviewing previous incarnations of the source code, and to the other members of the JSR166 Expert Group (Joe Bowbeer, Josh Bloch, Brian Goetz, David Holmes, and Tim Peierls) as well as Bill Pugh, for helping with design and specifications and commenting on drafts of this paper. Portions of this work were made possible by a DARPA PCES grant, NSF grant EIA-0080206 (for access to the 24way Sparc) and a Sun Collaborative Research Grant.\n参考文献 Agesen, O., D. Detlefs, A. Garthwaite, R. Knippel, Y. S.Ramakrishna, and D. White. An Efficient Meta-lock for Implementing Ubiquitous Synchronization. ACM OOPSLA Proceedings, 1999.\nAndrews, G. Concurrent Programming. Wiley, 1991.\nBacon, D. Thin Locks: Featherweight Synchronization for Java. ACM PLDI Proceedings, 1998.\nBuhr, P. M. Fortier, and M. Coffin. Monitor Classification,ACM Computing Surveys, March 1995.\nCraig, T. S. Building FIFO and priority-queueing spin locks from atomic swap. Technical Report TR 93-02-02,Department of Computer Science, University of Washington, Feb. 1993.\nGamma, E., R. Helm, R. Johnson, and J. Vlissides. Design Patterns, Addison Wesley, 1996.\nHolmes, D. Synchronisation Rings, PhD Thesis, Macquarie University, 1999.\nMagnussen, P., A. Landin, and E. Hagersten. Queue locks on cache coherent multiprocessors. 8th Intl. Parallel Processing Symposium, Cancun, Mexico, Apr. 1994.\nMellor-Crummey, J.M., and M. L. Scott. Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. ACM Trans. on Computer Systems,February 1991\nM. L. Scott and W N. Scherer III. Scalable Queue-Based Spin Locks with Timeout. 8th ACM Symp. on Principles and Practice of Parallel Programming, Snowbird, UT, June 2001.\nSun Microsystems. Multithreading in the Solaris Operating Environment. White paper available at http://wwws.sun.com/software/solaris/whitepapers.html 2002.\nZhang, H., S. Liang, and L. Bak. Monitor Conversion in a Multithreaded Computer System. United States Patent 6,691,304. 2004.\n","date":"2021-03-22T00:00:00Z","permalink":"http://localhost:1313/p/j.u.c-%E5%90%8C%E6%AD%A5%E6%A1%86%E6%9E%B6aqs-%E6%A1%86%E6%9E%B6/","title":"J.U.C 同步框架（AQS 框架）"},{"content":"Docker安装Nginx 1 2 3 4 5 docker run --name nginx -p 8000:80 -d --privileged=true \\ -v $PWD/log:/var/log/nginx \\ -v $PWD/html:/usr/share/nginx/html \\ -v $PWD/conf/conf.d:/etc/nginx/conf.d \\ -v $PWD/conf/nginx.conf:/etc/nginx/nginx.conf --restart=always nginx Docker安装FTP docker search vsftpd #寻找vsftpd的镜像 #假如我们找到一个最多引用的，叫fauria/vsftpd docker pull fauria/vsftpd #把镜像pull到本地 1 2 3 4 5 6 7 docker run -d -p 21:21 -p 20:20 -p 21100-21110:21100-21110 --name vsftpd \\ -v /opt/ftp_file:/home/vsftpd \\ -e FTP_USER=username \\ -e FTP_PASS=password \\ -e PASV_ADDRESS=xxx.xxx.xxx.xxx \\ -e PASV_MIN_PORT=21100 \\ -e PASV_MAX_PORT=21110 --restart=always fauria/vsftpd -p进行端口绑定映射 -v进行文件目录的映射 FTP_UESR 和FTP_PASS如果设定了会在container里面的 /etc/vsftpd/virtual_users.txt PASV_MIN_PORT和PASV_MAX_PORT映射的是被动模式下端口使用范围 PASV_ADDRESS指的的宿主机地址\n1、我们先进入container里面\n1 docker exec -i -t vsftpd bash 2、修改并生成虚拟用户模式下的用户db文件\n1 vi /etc/vsftpd/virtual_users.txt #编辑配置文件写入用户跟密码 假如我们添加了user用户\n1 2 3 mkdir /home/vsftpd/user #建立新用户文件夹 /usr/bin/db_load -T -t hash -f /etc/vsftpd/virtual_users.txt /etc/vsftpd/virtual_users.db Docker 配置阿里镜像 1 2 3 4 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://2g2ux2e3.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2021-03-16T00:00:00Z","permalink":"http://localhost:1313/p/docker%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E9%9B%86%E5%90%88/","title":"Docker安装软件集合"},{"content":"创建表空间 1 2 3 4 5 6 ./mysql -uroot -p -hlocalhost -P3306 mysql\u0026gt; CREATE DATABASE cicro DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; mysql\u0026gt; CREATE USER \u0026#39;cicrouser\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;cicropassword\u0026#39;; mysql\u0026gt; GRANT ALL PRIVILEGES ON cicro.* TO \u0026#39;cicrouser\u0026#39;@\u0026#39;%\u0026#39;; mysql\u0026gt; flush privileges; ","date":"2021-03-16T00:00:00Z","permalink":"http://localhost:1313/p/mysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"MySQL常用命令"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 #!/bin/sh BASE_HOME=/deveye/dsp SERVER_PORT=8960 # set customer varibales ulimit -n 65535 export JAVA_HOME=$BASE_HOME/opt/jdk export JAVA_OPTS=\u0026#34;-server -Xms16000m -Xmx16000m -XX:PermSize=128m -XX:MaxPermSize=256m -Djava.security.egd=file:/dev/./urandom\u0026#34; log () { echo \u0026#34;========\u0026gt;\u0026gt; $1 \u0026lt;\u0026lt;========\u0026#34; } get_pid_by_port () { PID=$(netstat -anp | grep $1 | grep LISTEN | awk \u0026#39;{printf $7}\u0026#39; | cut -d/ -f1) if [[ \u0026#34;$PID\u0026#34; != \u0026#34;\u0026#34; \u0026amp;\u0026amp; \u0026#34;${PID:0:1}\u0026#34; != \u0026#34;-\u0026#34; ]] ; then echo $PID else echo -1 fi } kill_by_port () { PID=$(get_pid_by_port $1) echo \u0026#34;[$1] pid: [$PID]\u0026#34; if [ \u0026#34;$PID\u0026#34; != \u0026#34;-1\u0026#34; ] ; then kill -9 $PID fi } case \u0026#34;$1\u0026#34; in \u0026#39;start\u0026#39; ) log \u0026#34;cdi start ...\u0026#34; /deveye/opt/rsync-client/bin/rsync-dsp $BASE_HOME/opt/tomcat/bin/startup.sh log \u0026#34;cdi start ok.\u0026#34; ;; \u0026#39;stop\u0026#39; ) log \u0026#34;cdi stop ...\u0026#34; kill_by_port $SERVER_PORT sleep 1s log \u0026#34;cdi stop ok.\u0026#34; ;; \u0026#39;restart\u0026#39; ) $0 stop sleep 1s $0 start ;; \u0026#39;cc\u0026#39; ) \u0026gt; $BASE_HOME/opt/tomcat/logs/catalina.out exit 1 ;; \u0026#39;tc\u0026#39; ) tail -f $BASE_HOME/opt/tomcat/logs/catalina.out exit 1 ;; \u0026#39;vc\u0026#39; ) vim $BASE_HOME/opt/tomcat/logs/catalina.out exit 1 ;; * ) echo \u0026#34;Usage: $0 [ start | stop | restart | cc | tc | vc ]\u0026#34; exit 1 ;; esac ","date":"2021-03-16T00:00:00Z","permalink":"http://localhost:1313/p/tomcat%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC/","title":"Tomcat运维脚本"},{"content":" 转载自: https://juejin.im/post/5c3ca16ff265da617573f9a4\n《刻意练习》是一本神奇的魔法书，它用大量的事实案例和数据来证明了刻意练习能给一个人带来的巨大改变。更为难能可贵的是，它不仅仅只是介绍刻意练习的好处，还给读者介绍了刻意练习的方法和注意事项，可以说是干货满满的一本书。\n本文想以“学习编程”为例，结合《刻意练习》这本书教给我们的方式方法，阐述如何通过刻意练习来提高自己的编程水平。\n关于练习 **不断重复只是“天真的练习”，无法带来进步。“正确的练习”需要好导师、有目标、有反馈。**所以如果想要提高编程水平，光靠一味闷着头努力写代码是不够的，有些人写了几年的CRUD，可能整体的技术水平还不及刚毕业的同学。\n一个好的导师很难得，他不仅要自己在编程水平是有一定的成就，还应该具有一些教育方面的经验，才能更好的指导你。一般来说，大一点的公司都会有老人带新人的机制，可以利用这个来找一个比较好的前辈带一带。另外就是通过看书或看视频其实也是一种很不错的学习方式，写书和出视频的老师自然是具备上述条件的。\n有目标指的是应该要有明确的目标，而不是一个宽泛的目标。比如“我要提高Java水平”明显就是一个宽泛的目标，无法量化。明确的目标应该是什么样子呢？比如，我要学习JVM的基础知识，我要学完23种设计模式等等。一个好的目标还应该是可分解的，有时间或成果量化的。比如，我需要在一个月内学习完Java多线程技术，第一周学习多线程模型，第二周学习多线程基本的类和接口，第三周阅读JDK里面关于多线程方面的工具类的源码，第四周写多线程案例Demo，最后产出一个Java多线程系列笔记或者博客。\n有反馈指的是可以量化的反馈。比如写一篇技术博客，有多少阅读量，点赞量，评论量？写一个开源项目有多少star，做一个LeetCode有没有通过，耗时如何？\n上述算是对“有目的的练习”的一个阐述。刻意练习是在有目的的练习基础上的。总结起来，有目的的练习应该具有以下四个特点：\n1.有目的的练习具有定义明确的特定目标 2.有目的的练习是专注的 3.有目的的练习包含反馈 4.有目的的练习需要走出舒适区\n对于任何类型的练习，这是一条基本的真理：如果你从来不迫使自己走出舒适区，便永远无法进步。\n关于心理表征 《刻意练习》这本书用了大量的篇幅来介绍心理表征。作者认为，刻意练习的核心之一在于通过练习来创建大量的心理表征，然后再使用这些心理表征反过来帮助练习。\n那心理表征到底是什么？\n我认为**它是一个人学习某样东西的时候，自己心中形成的一个体系架构。**比如我们学习算法，就会形成一个关于算法的体系架构，也就是心理表征。而当我们再学习到Mysql的底层索引原理的时候，就会想到算法关于平衡树方面的知识；当我们学习JDK源码里关于集合框架的时候，就会想到链表、栈与队列、红黑树等等。\n我们的知识形成了一个循环，学得越多，懂得越多。当我们积累了大量的知识以后，再学一样有关联的东西，就能快速学会。\n刻意练习 刻意练习提倡“边干边学”，**它使人们熟悉练习的习惯，并思考如何练习。**这与我们学习编程的理念是一样的，几乎没有人会对你说：你只需要看书，看博客，看视频就能学会编程。有经验的前辈一般会告诉你，要有输入，也要有输出。学习了的东西，要通过写代码或者做笔记或者写博客的方式，让知识变成你自己的，更加牢固。\n你通过写代码，不断地写代码来提高自己的编程水平，然后通过思考，反思来决定该如何写代码才能写得更好。\n传统的方法也一直是先找出关于正确方法的信息，然后很大程度上让学生去运用那些知识。刻意练习则完全相反，它只聚焦于绩效和表现，以及怎样提高绩效和表现。\n编程也是一样，老板和上级其实真正在意的并不是你懂多少理论，而是你写得代码质量好不好，你能不能快速地实现他们需要的功能，能不能解决技术难题。\n你的代码写得比别人快，你的代码写得比别人漂亮，你能快速解决别人不能解决的难题，那你就牛逼。\n关于专注与坚持 刻意练习里面有一个观点颠覆了我以前的认知。我一度认为，一个人能不能专注，能不能坚持做一件事，除了热爱，那必然是意志力越高的人越能专注和坚持。\n然而刻意练习告诉我，**意志力根本不存在！**所谓意志力，其实是保持动机与专注的结果。\n我们先来看看如何让自己保持专注，**不专注的练习是没有效果的。**刻意练习提供了一个观点，如果练习的时间更短，那就会有更好的注意力。\n对于这个观点我是绝对认同的。比如看书，如果想一次性看完一本书，那对于一般人来说绝对是非常困难的。但是如果把它拆成一章一章，每天看一点，那就会好很多。而在日常的工作中或者学习中，我们可以使用“番茄钟”来管理自己的时间与保持专注。这里不具体介绍番茄钟，有兴趣的同学自己去了解一下，亲测有用！一个番茄钟25分钟，不多不少刚刚好。\n再来谈谈动机。对于一个程序员来说，动机是再明显不过的了：升职加薪变大佬。但有时候这个动机并不能转化为一种强有力的动力来促使我们去学习，去提高技术水平。而某些太强烈的动机（比如想跳槽）又很难持续保持。\n《刻意练习》告诉我们，我们要保持动机，要么强化继续前行的理由，要么弱化停下脚步的理由。\n仍然以学习算法为例。要强化继续前行的理由，我们可以在学习到一定阶段给自己一些小的奖励，比如刷完100个算法题，给自己买个好的键盘或者耳机。还有来自朋友、同事、家人乃至默认人的鼓励也很重要。我在网上写博客分享给大家，如果读者的点赞或者好评，那也是非常能激励我们继续学习的！\n而弱化停下脚步的理由。比如练习累了就合理休息一下，学习累了就暂时玩一下，如果觉得自己一个人学技术太孤独，就找一群小伙伴一起学习或者加入一个技术社区。目标要精心设置且合理，这样才能得到达到目标的成就感，不会因为达不到目标而气馁放弃。\n愿你以梦为马，剑指天涯。\n","date":"2021-01-17T00:00:00Z","permalink":"http://localhost:1313/p/%E5%88%BB%E6%84%8F%E7%BB%83%E4%B9%A0%E4%BB%A5%E5%AD%A6%E4%B9%A0%E7%BC%96%E7%A8%8B%E4%B8%BA%E4%BE%8B/","title":"《刻意练习》：以学习编程为例"},{"content":"工作中常用到的Reids命令 模糊匹配key并批量删除 1 redis-cli -u redis://password@ip:port/database keys \u0026#34;business:data:10103*\u0026#34; | xargs redis-cli -u redis://password@ip:port/database del ","date":"2020-10-28T00:00:00Z","permalink":"http://localhost:1313/p/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Redis常用命令"},{"content":"修改commit信息主要有这几种情况: 刚刚commit，还没有push，使用git commit --amend 刚刚push，要修改最近一个push的commit信息，使用git commit --amend 修改历史push的commit信息，使用git rebase -i HEAD~n【其中的n为记录数】，配合2中的命令 注意： 其中1、2两种情况的修改方式是一样的，但是git log的记录是不同的,第三种方式也是把需要修改的记录调整为最新的提交，然后使用2的方式修改。\n","date":"2020-10-23T00:00:00Z","permalink":"http://localhost:1313/p/git%E4%BF%AE%E6%94%B9commit%E4%BF%A1%E6%81%AF/","title":"Git修改commit信息"},{"content":" 查看配置文件只匹配不是以“#”开头的行 1 cat .zshrc | grep -v \u0026#34;^#\u0026#34; \u0026gt; profile.txt 使用tail查看指定行以后的N行日志 1 tail -n +358653 catalina.2021-01-12.out|head -n 20 ","date":"2020-09-27T00:00:00Z","permalink":"http://localhost:1313/p/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Linux常用命令"},{"content":"场景 一般情况下，我们写完代码后会执行:\n1 2 git add . git commit -m \u0026#34;xxx\u0026#34; 但是执行完后，想撤回怎么办？可以执行以下命令:\n1 git reset --soft HEAD^ 这样就可以撤回你的提交，并且不会丢失提交前修改的内容.\n理解 HEAD^ 代表上一个版本，同等于HEAD~1，如果进行了两次提交，可以写成HEAD~2\n参数\n--mixed\n默认参数，不删除工作空间改动的代码，只撤回提交，并且撤回git add .操作\n--soft\n不删除工作空间改动的代码，撤销提交，但是不撤回git add . 操作\n--hard\n删除工作空间改动的代码，撤销commit，撤销git add .，直接回退到上次commit\n最后 如果commit注释写错了，只是想改一下注释，只需要：\n1 git commit --amend 此时会进入默认vim编辑器，修改注释完毕后保存就好了。\n","date":"2020-08-21T00:00:00Z","permalink":"http://localhost:1313/p/git-commit%E4%B9%8B%E5%90%8E%E6%92%A4%E9%94%80commit/","title":"'git commit之后，撤销commit'"},{"content":"Description git rebase 和 git merge 一样都是用于从一个分支获取并且合并到当前分支，但是他们采取不同的工作方式，以下面的一个工作场景说明其区别.\n如图所示：你在一个feature分支进行新特性的开发，与此同时，master 分支的也有新的提交。\n为了将master 上新的提交合并到你的feature分支上，你有两种选择：merging or rebasing\nmerge 执行以下命令:\n1 2 git checkout feature git merge master 或者执行更简单的： git merge master feature\n那么此时在feature上git 自动会产生一个新的commit(merge commit) look like this：\n**merge 特点：**自动创建一个新的commit,如果合并的时候遇到冲突，仅需要修改后重新commit **优点：**记录了真实的commit情况，包括每个分支的详情 **缺点：**因为每次merge会自动产生一个merge commit，所以在使用一些git 的GUI tools，特别是commit比较频繁时，看到分支很杂乱。\nrebase 本质是变基,执行以下命令：\n1 2 git checkout feature git rebase master **rebase 特点：**会合并之前的commit历史 **优点：**得到更简洁的项目历史，去掉了merge commit **缺点：**如果合并出现代码问题不容易定位，因为re-write了history 合并时如果出现冲突需要按照如下步骤解决\n修改冲突部分 git add git rebase \u0026ndash;continue （如果第三步无效可以执行 git rebase \u0026ndash;skip） 不要在git add 之后习惯性的执行 git commit命令 The Golden Rule of Rebasing rebase 的黄金法则: never use it on public branches(不要在公共分支上使用) 比如说如下场景：如图所示 如果你rebase master 到你的feature分支： rebase 将所有master的commit移动到你的feature 的顶端。问题是：其他人还在original master上开发，由于你使用了rebase移动了master，git 会认为你的主分支的历史与其他人的有分歧，会产生冲突。 所以在执行git rebase 之前 问问自己，\n会有其他人看这个分支么？ IF YES 不要采用这种带有破坏性的修改commit 历史的rebase命令 IF NO OK，随你便，可以使用rebase\nSummary 总结 如果你想要一个干净的，没有merge commit的线性历史树，那么你应该选择git rebase 如果你想保留完整的历史记录，并且想要避免重写commit history的风险，你应该选择使用git merge\n参考资料 https://www.atlassian.com/git/tutorials/merging-vs-rebasing/conceptual-overview https://git-scm.com/book/zh/v2/Git-分支-变基 https://git-scm.com/book/zh/v2/Git-分支-分支的新建与合并#_basic_merging\n","date":"2020-08-19T00:00:00Z","permalink":"http://localhost:1313/p/git-rebase%E5%92%8Cgit-merge%E7%9A%84%E5%8C%BA%E5%88%AB/","title":"git rebase和git merge的区别"},{"content":"使用nginx做反向代理的时候，可以简单的直接把请求原封不动的转发给下一个服务。设置proxy_pass请求只会替换域名，如果要根据不同的url后缀来访问不同的服务，则需要通过如下方法：\n方法一：加\u0026quot;/\u0026quot; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 server { listen 8000; server_name abc.com; access_log \u0026#34;pipe:rollback /data/log/nginx/access.log interval=1d baknum=7 maxsize=1G\u0026#34; main; location ^~/user/ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; proxy_pass http://user/; } location ^~/order/ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; proxy_pass http://order/; } } ^~/user/表示匹配前缀是user的请求，proxy_pass的结尾有/， 则会把/user/*后面的路径直接拼接到后面，即移除user。\n方法二：rewrite 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 location ^~/user/ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; rewrite ^/user/(.*)$ /$1 break; proxy_pass http://user; } location ^~/order/ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; rewrite ^/order/(.*)$ /$1 break; proxy_pass http://order; } } proxy_pass结尾没有/， rewrite重写了url。\nlocation匹配命令 1 2 3 4 5 ~ #波浪线表示执行一个正则匹配，区分大小写 ~* #表示执行一个正则匹配，不区分大小写 ^~ #^~表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录 = #进行普通字符精确匹配 @ #\u0026#34;@\u0026#34; 定义一个命名的 location，使用在内部定向时，例如 error_page, try_files location 匹配的优先级(与location在配置文件中的顺序无关) = 精确匹配会第一个被处理。如果发现精确匹配，nginx停止搜索其他匹配。\n普通字符匹配，正则表达式规则和长的块规则将被优先和查询匹配，也就是说如果该项匹配还需去看有没有正则表达式匹配和更长的匹配。\n^~ 则只匹配该规则，nginx停止搜索其他匹配，否则nginx会继续处理其他location指令。\n最后匹配理带有\u0026quot;~\u0026ldquo;和\u0026rdquo;~*\u0026ldquo;的指令，如果找到相应的匹配，则nginx停止搜索其他匹配；当没有正则表达式或者没有正则表达式被匹配的情况下，那么匹配程度最高的逐字匹配指令会被使用。\n","date":"2020-08-19T00:00:00Z","permalink":"http://localhost:1313/p/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/","title":"Nginx反向代理配置"},{"content":"简介 在一些分布式系统中，应用与应用之间是相互独立部署的，Java应用运行在不同的JVM中，所以，在操作一些共享资源的时候，使用JDK提供的Lock工具类时就有些力不从心，这时候就需要借助外力来实现分布式一致性问题。\n通常会使用以下三种方式进行实现：\n基于数据库实现分布式锁(悲观锁机制) Zookeeper分布式锁 Redis分布式锁 下面简单对比几种方式的优缺点：\n方式 优点 缺点 数据库 实现简单、易于理解 对数据库压力大 Redis 易于理解 自己实现、不支持阻塞 Zookeeper 支持阻塞 需要理解Zookeeper、程序复杂 Curator 提供锁的方法 依赖Zookeeper、强一致 Redisson 提供锁的方法、可阻塞 安全和活性的保证 Redis官方文档提出以下三点作为分布式锁的最低保证：\n互斥，在任何给定时刻，只有一个客户端可以持有锁 无死锁，最终，即使锁定资源的客户端崩溃或分区，也始终可以获得锁 容错能力，只要大多数Redis节点都处于运行状态，客户端就可以获取和释放锁 基于主备架构实现的不足 使用Redis实现分布式锁最简单的方法就是加锁的时候创建一个带有过期时间Key(这样是为了防止出现死锁)，当客户端需要释放锁的时候删除这个Key。\n从表面上看没有什么问题，但是当Redis出现宕机的时候怎么办？为了解决单点故障问题，我们可以添加一个从节点，当主节点不可用的时候，切换到从节点，但是这样实际上是不可行的，因为Redis使用的是异步复制。\n该模型明显存在的竞争条件:\n客户端A获取主节点的锁 主节点将Key同步到从节点之前发生宕机 从节点切换成主节点 客户端B获取到相同资源的锁，此时A和B同时持有锁，违反了安全性 单实例方案 假设可以克服以上单节点不足的问题，我们可以使用以下命令实现分布式锁：\n1 SET resource_name my_random_value NX PX 30000 该命令仅在Key不存在(NX)、且到期时间(PX)为30000毫秒的情况下才设置Key。Key的值为一个随机数，该值要求必须全局唯一，使用全局唯一值是为了在删除Key的时候，Key的值是我们之前设置的值时，才删除Key。(Tips:我们总不能删除其他客户端设置的Key吧？)\n可以使用以下Lua脚本完成，因为Lua脚本可以保证两个操作的原子性。\n1 2 3 4 5 if redis.call(\u0026#34;get\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;,KEYS[1]) else return 0 end RedLock算法 在算法的分布式版本中，我们假设有5个Master节点，这些节点是完全独立的，我们将各个节点部署在不同的服务器中，以保证他们同时出现故障的概率。\n为了获取锁，客户端执行以下操作：\n客户端获取当前时间的时间戳 客户端尝试在N（N=5）个节点上以相同的Key和Value获取一个锁(此处和单实例方式相同) 客户端通过从当前时间中减去在步骤1中获得的时间戳，来计算获取锁所花费的时间，当客户端能够在大多数实例（至少3个）中获取锁时 ，并且获取锁所花费的总时间小于锁有效时间，则认为已获取锁。 如果获取了锁，则将其有效时间视为初始有效时间减去经过的时间 如果客户端由于某种原因（无法锁定N / 2 + 1实例或有效时间为负数）而未能获得该锁，它将尝试解锁所有实例 释放锁 释放锁很简单，只需在所有实例中释放锁（即使之前在某个实例中没有获取到锁）。\nRedLock注意点 先假设client获取所有实例，所有实例包含相同的key和过期时间(TTL) ,但每个实例set命令时间不同导致不能同时过期，第一个set命令之前是T1,最后一个set命令后为T2,则此client有效获取锁的最小时间为TTL-(T2-T1)-时钟漂移 对于以N/2+ 1(也就是一半以 上)的方式判断获取锁成功，是因为如果小于一半判断为成功的话，有可能出现多个client都成功获取锁的情况，从而使锁失效 一个client锁定大多数事例耗费的时间大于或接近锁的过期时间，就认为锁无效，并且解锁这个redis实例(不执行业务) ;只要在TTL时间内成功获取一半以上的锁便是有效锁;否则无效 系统具有活性的三大特征 能够自动释放锁 再获取锁失败（不到一半以上），或任务完成后能够释放锁，不用等到其自动过期 再客户端重试获取锁之前（第一次失败到第二次失败之间的间隔时间）大于获取锁消耗的时间 参考Redis官方文档 https://redis.io/topics/distlock RedLock分析 [http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html][http://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html]\n","date":"2020-07-09T00:00:00Z","permalink":"http://localhost:1313/p/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"Redis分布式锁"},{"content":"Sentinel的分布式特征 Redis Sentinel是一个分布式系统： Sentinel本身的设计是在为多个Sentinel进程协同合作的配置中运行。\n当多个哨兵就给定的主机不再可用的事实达成共识时，将执行故障检测，降低了误报的可能性。 即使不是所有的Sentinel进程都在工作，Sentinel仍可正常工作，从而使系统能够应对故障。毕竟，拥有故障转移系统本身就是一个单点故障， 运行哨兵 1 redis-sentinel /path/to/sentinel.conf redis-sentinel是redis-server的一个软链接，所以也可以使用以下方法：\n1 redis-server /path/to/sentinel.conf --sentinel 两种方法的工作原理相同。\n但是，再运行Sentinel时必须指定配置文件，因为系统将使用此文件来保存当前状态，以便在重新启动时重新加载。如果未指定文件，则会启动失败。\nSentinels默认情况下会监听TCP端口26379连接，因此必须打开26379端口。\nSentinel的基础知识 一个健壮的集群至少需要三个Sentinel实例 应该将三个Sentinel实例部署在不同的机器上 因为Redis使用的是异步复制，所以不能保证在故障转移期间保证数据的写入。 配置哨兵 Redis的源码包包含一个sentinel.conf文件可用于配置Sentinel，典型的最小配置如下所示：\n1 2 3 4 sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 60000 sentinel failover-timeout mymaster 180000 sentinel parallel-syncs mymaster 1 sentinel monitor含义如下：\n1 sentinel monitor \u0026lt;master-group-name\u0026gt; \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; \u0026lt;quorum\u0026gt; \u0026lt;master-group-name\u0026gt; 指主节点名称，\u0026lt;ip\u0026gt; IP地址 \u0026lt;port\u0026gt;端口号，重点说一下\u0026lt;quorum\u0026gt;： 假如有5个Sentinel进程，并且给定主服务器的quorum置为2，则将发生以下情况：\n如果有两个哨兵同时发现主节点不可访问，则其中一个哨兵将尝试启动故障转移。 如果有三个哨兵同时发现主节点不可访问，则将启动故障转移。 1 sentinel down-after-milliseconds down-after-milliseconds是指Sentinel在指定的时间内没有获得实例的响应，则认为实例已关闭。\n1 sentinel parallel-syncs parallel-syncs 设置每次可以对几个副本进行同步数据\nRedis 哨兵部署示例 经典三节点最小部署 1 2 3 4 5 6 7 8 9 10 11 +----+ | M1 | | S1 | +----+ | +----+ | +----+ | R2 |----+----| R3 | | S2 | | S3 | +----+ +----+ Configuration: quorum = 2 如果主M1发生故障，则S2和S3将达成协议，并能够开启故障转移，从而使客户端能够继续使用。\n模拟发生网络分区 1 2 3 4 5 6 7 8 9 10 11 +----+ | M1 | | S1 | \u0026lt;- C1 (writes will be lost) +----+ | / / +------+ | +----+ | [M2] |----+----| R3 | | S2 | | S3 | +------+ +----+ 在这种情况下，网络分区隔离了旧的主数据库M1，因此副本R2被提升为主数据库。但是，与旧主服务器位于同一分区中的客户端（例如C1）可能会继续向旧主服务器写入数据。该数据将永远丢失，因为当分区恢复正常时，主服务器将被重新配置为新主服务器的副本，从而造成数据丢失。\n使用以下Redis复制功能可以缓解此问题，如果主服务器检测到副本数量没有达到指定的副本数据，则停止接受数据写入。\n1 2 3 4 # 最小副本数量 min-replicas-to-write 1 # 发送异步确认的最大时间 min-replicas-max-lag 10 ","date":"2020-07-07T00:00:00Z","permalink":"http://localhost:1313/p/redis%E5%93%A8%E5%85%B5/","title":"Redis哨兵"},{"content":"本文主要对比常用的三种中间件优劣势，包含RocketMQ、Kafka、RabbitMQ。\nKafka 优势 Kafka的吞吐量几乎是行业里最优秀的，在常规的机器配置下，一台机器可以达到每秒十几万的QPS，相当的强悍。 Kafka性能也很高，基本上发送消息给Kafka都是毫秒级的性能。可用性也很高，Kafka是可以支持集群部署的，其中部分机器宕机是可以继续运行的。 Kafka技术在各大公司里的使用，基本行业里的一个标准，是把Kafka用在用户行为日志的采集和传输上，比如大数据团队要收集APP上用户的一些行为日志，这种日志就是用Kafka来收集和传输的。 劣势 Kafka比较为人诟病的一点，似乎是丢数据方面的问题，因为Kafka收到消息之后会写入一个磁盘缓冲区里，并没有直接落地到物理磁盘上去，所以要是机器本身故障了，可能会导致磁盘缓冲区里的数据丢失。 Kafka另外一个比较大的缺点，就是功能非常的单一，主要是支持发送消息给他，然后从里面消费消息，其他就没有什么额外的高级功能了。所以基于Kafka有限的功能，可能适用的场景并不是很多。 总结 Kafka适用于那种日志适当丢失数据是没有关系的，而且一般量特别大，要求吞吐量要高，一般就是收发消息，不需要太多的高级功能，所以Kafka是非常适合这种场景的。\nRabbitMQ 优势 RabbitMQ的优势在于可以保证数据不丢失，也能保证高可用性，即集群部署的时候部分机器宕机可以继续运行，然后支持部分高级功能，比如说死信队列，消息重试之类的，这些是他的优点。 在RocketMQ出现之前，国内大部分公司都从ActiveMQ切换到RabbitMQ来使用，包括很多一线互联网大厂，而且直到现在都有很多中小型公司在使用RabbitMQ，所以说RabbitMQ网上的资料相对多，而且社区非常活跃，更新频率非常快。 劣势 RabbitMQ的吞吐量是比较低，一般就是每秒几万的级别，所以如果遇到特别特别高并发的情况下，支撑起来是有点困难的。 RabbitMQ进行集群扩展的时候（也就是加机器部署），比较麻烦。 另外还有一个较为致命的缺陷，就是他的开发语言是erlang，国内很少有精通erlang语言的工程师，因此也没办法去阅读他的源代码，甚至修改他的源代码。 总结 现在行业里的一个情况是，很多BAT等一线互联网大厂都切换到使用更加优秀的RocketMQ了，但是很多中小型公司觉得RabbitMQ基本可以满足自己的需求还在继续使用中，因为中小型公司并不需要特别高的吞吐量，RabbitMQ已经足以满足他们的需求了，而且也不需要部署特别大规模的集群，也没必要去阅读和修改RabbitMQ的源码。\nRocketMQ 优势 RocketMQ的吞吐量很高，单机可以达到10万QPS以上，而且可以保证高可用性，性能很高，而且支持通过配置保证数据绝对不丢失，可以部署大规模的集群，还支持各种高级的功能，比如说延迟消息、事务消息、消息回溯、死信队列、消息积压，等等。\nRocketMQ是基于Java开发的，符合国内大多数公司的技术栈，很容易就可以阅读他的源码，甚至是修改他的源码。\nRocketMQ是非常适合用在Java业务系统架构中的，因为他很高的性能表现，还有他的高阶功能的支持，可以让我们解决各种业务问题。\n劣势 RocketMQ也有一点美中不足的地方，就是经过调查发现，RocketMQ的官方文档相对简单一些，但是Kafka和RabbitMQ的官方文档就非常的全面和详细，这可能是RocketMQ目前唯一的缺点。 总结 RocketMQ相对来说比较完美的一个消息中间件，在支撑高吞吐量的同时，而且还支持很多高阶的功能，很适合以Java为技术栈的公司使用。\n","date":"2020-05-14T00:00:00Z","permalink":"http://localhost:1313/p/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E9%80%89%E5%9E%8B/","title":"消息中间件选型"},{"content":"1、了解消息中间件之前先了解一下什么是“同步”? 通常业务系统直接的调用如下图所示:\n假设系统A收到了一个请求，可能是用户通过浏览器或者APP发起的，这时候系统A收到请求后马上去调用系统B，然后系统B再把返回结果返回给系统A，系统A才能返回给用户。如下图所示：\n以上就是所谓的**“同步”**调用。这个同步的意思就是各个系统联动都是同步依次进行的，一个系统先动，然后立马带动另外一个系统一起动，最后大家依次干完活以后再返回结果。\n2、如何依托消息中间件实现异步？ 我们往系统A和系统B之间加入一个消息中间件，简称为“MQ”，也就是消息队列。\n加入消息队列之后如何通信呢？\n其实就是系统A执行完逻辑后给MQ中发送一条消息，然后就直接把结果返回给用户了。\n（注：前提是系统A返回给用户的结果不依赖于系统B的返回结果。假设系统B为短信系统，系统A向MQ发送一条发送短信的消息指令，系统A并不关心短信是否立即发送，只要最终在有效的时间内发送成功就行了。）\n如上图所示，系统B什么时候执行自己的任务呢？\n这时候系统B根据自己的情况，可能是系统A投递消息到MQ之后的1秒内，也可能是1分钟之后，多长时间都有可能，不管多长时间，系统B肯定会从MQ里获取到一条属于自己的消息。\n3、消息中间件到底有什么用？ 假设系统A要调用系统B干一些事，然后系统A先执行一些操作，需要耗费20ms，接着系统B执行一些操作，需要200ms，所以总共需要220ms。如下图所示：\n如果在系统A和系统中间加一个MQ呢？\n系统A干完自己的事情耗时20ms，然后发一个消息到MQ耗时5ms，然后就直接返回结果给用户，总计耗时25ms。系统B从MQ中获取消息花费200ms和用户就没有关系了。所以用户只需等待25ms就收到结果了。如下图所示：\n假设系统A调用系统B出现故障呢？因为系统A调用系统B肯定返回异常，此时系统A是不是也得返回异常给用户？而系统A是不是还要去处理这个异常？\n这一切是因为系统A和系统B通过同步调用的模式耦合在一起，所以系统B一旦出现故障，很肯能影响系统A也有故障，而且系统A还得去关心系统B的故障，去处理对应的异常。\n如果在系统A和系统B中间加一个消息中间件，系统A就不用关心系统B是否出现故障了，因为那是系统B自己的事，等系统B故障恢复以后，就继续执行它自己的事，此时就对系统A没任何影响了。\n为什么会有这样的效果呢？正式因为通过引入MQ，两个系统实现了异步化调用，也就实现了解耦，所以相互之间并没有任何影响。\n5、流量削峰 假设系统A是不操作数据库的，因此只要多部署几台机器，就可以抗下每秒1万的请求，比如部署个20台机器，就可以轻松抗下每秒上万请求。\n然后系统B是要操作一台数据库服务器的，那台数据库的上限是接收每秒6000请求，那么系统B无论部署多少台机器都没用，因为他依赖的数据库最多只能接收每秒6000请求。\n如下图所示：\n假设现在有1万的QPS请求到了系统A，由于系统A部署了20台机器，所以可以抗住1万QPS。然后系统A会瞬间把1万QPS转发给系统B，假设系统B也抗住了1万QPS，但是系统B对数据库发起了1万QPS的请求，数据库一定会瞬间被压垮。\n所以这时如果引入MQ，就可以解决这个问题了。MQ这个技术抗高并发的能力远远高于数据库，同样的机器配置下，如果数据库可以抗每秒6000请求，MQ至少可以抗每秒几万请求。\n为什么呢？因为数据库复杂啊，他要能够支持你执行复杂的SQL语句，支持事务等复杂的机制，支持你对数据进行增删改查，听着简单，其实是很复杂的！所以一般数据库单服务器也就支撑每秒几千的请求。\n所以只要你引入一个MQ，那么就可以让系统A把每秒1万请求都作为消息直接发送到MQ里，MQ可以轻松抗下来这每秒1万请求。\n接着，系统B只要慢慢的从MQ里获取消息然后执行数据库读写操作即可，这个获取消息的速度是系统B自己可以控制的，所以系统B完全可以用一个比较低的速率获取消息然后写入数据库，保证对数据库的QPS不要超过他的极限值6000。\n这个时候因为系统A发送消息到MQ很快，系统B从MQ消费消息很慢，所以MQ里自然会积压一些消息，不过不要紧，MQ一般都是基于磁盘来存储消息的，所以适当积压一些消息是可以的。当系统A的高峰过去，每秒可能就恢复到1000 QPS了，此时系统b还是以每秒6000QPS的速度获取消息写入数据库，那么自然MQ里积压的消息就会慢慢被消化掉了。\n所以这就是MQ进行流量削峰的效果，系统A发送过来的每秒1万请求是一个流量洪峰，然后MQ直接给扛下来了，都存储自己本地磁盘，这个过程就是流量削峰的过程，瞬间把一个洪峰给削下来了，让系统B后续慢慢获取消息来处理。\n6、总结 消息中间件的主要作用就是削峰解耦，提升系统的响应速度。\n","date":"2020-05-13T00:00:00Z","permalink":"http://localhost:1313/p/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%98%AF%E4%BB%80%E4%B9%88/","title":"消息中间件是什么?"},{"content":"反转链表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; ) func main() { head := \u0026amp;ListNode{ 1, \u0026amp;ListNode{ 2, \u0026amp;ListNode{ 3, \u0026amp;ListNode{ 4, \u0026amp;ListNode{ 5, nil}}, }, }, } for list := reverseList(head); list != nil; list = list.Next { fmt.Println(list.Val) } } type ListNode struct { Val int Next *ListNode } func reverseList(head *ListNode) *ListNode { var cur, prev *ListNode = head, nil for cur != nil { cur.Next, prev, cur = prev, cur, cur.Next } return prev } 交换相邻两个节点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package main import \u0026#34;fmt\u0026#34; func main() { head := \u0026amp;ListNode{ 1, \u0026amp;ListNode{ 2, \u0026amp;ListNode{ 3, \u0026amp;ListNode{ 4, nil}, }, }, } for list := swapPairs(head); list != nil; list = list.Next { fmt.Println(list.Val) } } type ListNode struct { Val int Next *ListNode } func swapPairs(head *ListNode) *ListNode { if head == nil || head.Next == nil { return head } newHead := head.Next head.Next = swapPairs(newHead.Next) newHead.Next = head return newHead } 判断链表是否有环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import \u0026#34;fmt\u0026#34; func main() { cycle := \u0026amp;ListNode{ 2, \u0026amp;ListNode{ 0, \u0026amp;ListNode{ -4, nil}}} cycle.Next.Next.Next = cycle head := \u0026amp;ListNode{ 3, cycle, } fmt.Println(hasCycle(head)) } type ListNode struct { Val int Next *ListNode } func hasCycle(head *ListNode) bool { if head == nil || head.Next == nil { return false } slow, fast := head, head for fast != nil \u0026amp;\u0026amp; fast.Next != nil { slow, fast = slow.Next, fast.Next.Next if slow == fast { return true } } return false } ","date":"2019-09-03T00:00:00Z","permalink":"http://localhost:1313/p/%E9%93%BE%E8%A1%A8/","title":"链表"},{"content":"排序算法 冒泡排序 双层循环,每次循环将最大的值放到数组的最后面,外层循环n次,内层循环n-i次完成排序,时间复杂度为O(n²)\n1 2 3 4 5 6 7 8 9 func bubbleSort(arr []int) { for i := 0; i \u0026lt; len(arr)-1; i++ { for j := 0; j \u0026lt; len(arr)-i-1; j++ { if arr[j] \u0026gt; arr[j+1] { arr[j], arr[j+1] = arr[j+1], arr[j] } } } } 选择排序 双层循环,每次循环找出arr[n-i]中最小的数与当前数进行交换,时间复杂度为O(n²)\n1 2 3 4 5 6 7 8 9 10 11 func selectSort(arr []int) { for i := 0; i \u0026lt; len(arr)-1; i++ { var min = i for j := i + 1; j \u0026lt; len(arr); j++ { if arr[min] \u0026gt; arr[j] { min = j } } arr[i], arr[min] = arr[min], arr[i] } } 插入排序 双层循环,类似打扑克牌调整牌的顺序,每次循环对当前数字顺序进行插入调整,时间复杂度为O(n²)\n1 2 3 4 5 6 7 8 9 10 11 func insertionSort(arr []int) { for i := range arr { preIndex := i - 1 current := arr[i] for preIndex \u0026gt;= 0 \u0026amp;\u0026amp; arr[preIndex] \u0026gt; current { arr[preIndex+1] = arr[preIndex] preIndex -= 1 } arr[preIndex+1] = current } } 归并排序 分治的思想,时间复杂度O(N*logN)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func mergeSort(arr []int) []int { if len(arr) \u0026lt; 2 { return arr } i := len(arr) / 2 left := mergeSort(arr[:i]) right := mergeSort(arr[i:]) result := merge(left, right) return result } func merge(left, right []int) []int { result := make([]int, 0) m, n := 0, 0 l, r := len(left), len(right) for m \u0026lt; l \u0026amp;\u0026amp; n \u0026lt; r { if left[m] \u0026gt; right[n] { result = append(result, right[n]) n++ } else { result = append(result, left[m]) m++ } } result = append(result, right[n:]...) result = append(result, left[m:]...) return result } 堆排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package heap func sink(array []int, parentIndex int, length int) { //保存父节点，用于最后的赋值 temp := array[parentIndex] //左子节点 childIndex := 2*parentIndex + 1 //是否有左子节点 for childIndex \u0026lt; length { //判断是否有右子节点，并且右子节点大于左子节点的值 if childIndex+1 \u0026lt; length \u0026amp;\u0026amp; array[childIndex+1] \u0026gt; array[childIndex] { childIndex++ } //如果父节点大于任何一个子节点的值直接跳出 if temp \u0026gt;= array[childIndex] { break } array[parentIndex] = array[childIndex] parentIndex = childIndex childIndex = 2*childIndex + 1 } array[parentIndex] = temp } func heapSort(array []int) { //构建大顶堆 for i := (len(array) - 2) / 2; i \u0026gt;= 0; i-- { sink(array, i, len(array)) } //将堆顶元素和最后一个元素交换，数组长度i--(相当于循环删除根顶部元素，然后sink 调整最大堆) for i := len(array) - 1; i \u0026gt; 0; i-- { array[i], array[0] = array[0], array[i] sink(array, 0, i) } } ","date":"2019-09-03T00:00:00Z","permalink":"http://localhost:1313/p/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","title":"排序算法"},{"content":" 排序算法 链表 ","date":"2019-09-03T00:00:00Z","permalink":"http://localhost:1313/p/%E7%AE%97%E6%B3%95%E4%B9%8B%E6%97%85/","title":"算法之旅"},{"content":" 1 \u0026lt;类型\u0026gt;: (类型的值见下面描述) \u0026lt;主题\u0026gt; (最多50个字) feat (新特性) fix (bug修复) docs (文档改动) style (格式化, 缺失分号等; 不包括生产代码变动) refactor (重构代码) test (添加缺失的测试, 重构测试, 不包括生产代码变动) chore (更新grunt任务等; 不包括生产代码变动)\n主题和内容以一个空行分隔 主题限制为最大50个字 主题行大写 主题行结束不用标点 主题行使用祈使名 内容每行72个字 内容用于解释为什么和是什么,而不是怎么做 内容多行时以\u0026rsquo;-\u0026lsquo;分隔 ","date":"2019-08-14T00:00:00Z","permalink":"http://localhost:1313/p/%E4%B8%80%E4%BB%BD%E5%BB%BA%E8%AE%AE%E7%9A%84git-commit-%E6%A8%A1%E7%89%88/","title":"一份建议的Git Commit 模版"},{"content":"\n一、新建代码库 # 在当前目录新建一个Git代码库\n$ git init\n# 新建一个目录，将其初始化为Git代码库\n$ git init [project-name]\n# 下载一个项目和它的整个代码历史\n$ git clone [url]\n二、配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）\n# 显示当前的Git配置\n$ git config \u0026ndash;list\n# 编辑Git配置文件\n$ git config -e [\u0026ndash;global]\n# 设置提交代码时的用户信息\n$ git config [\u0026ndash;global] user.name \u0026ldquo;[name]\u0026rdquo;\n$ git config [\u0026ndash;global] user.email \u0026ldquo;[email address]\u0026rdquo;\n三、增加/删除文件 # 添加指定文件到暂存区\n$ git add [file1] [file2] \u0026hellip;\n# 添加指定目录到暂存区，包括子目录\n$ git add [dir]\n# 添加当前目录的所有文件到暂存区\n$ git add .\n# 添加每个变化前，都会要求确认\n# 对于同一个文件的多处变化，可以实现分次提交\n$ git add -p\n# 删除工作区文件，并且将这次删除放入暂存区\n$ git rm [file1] [file2] \u0026hellip;\n# 停止追踪指定文件，但该文件会保留在工作区\n$ git rm \u0026ndash;cached [file]\n# 改名文件，并且将这个改名放入暂存区\n$ git mv [file-original] [file-renamed]\n四、代码提交 # 提交暂存区到仓库区\n$ git commit -m [message]\n# 提交暂存区的指定文件到仓库区\n$ git commit [file1] [file2] \u0026hellip; -m [message]\n# 提交工作区自上次commit之后的变化，直接到仓库区\n$ git commit -a\n# 提交时显示所有diff信息\n$ git commit -v\n# 使用一次新的commit，替代上一次提交\n# 如果代码没有任何新变化，则用来改写上一次commit的提交信息\n$ git commit \u0026ndash;amend -m [message]\n# 重做上一次commit，并包括指定文件的新变化\n$ git commit \u0026ndash;amend [file1] [file2] \u0026hellip;\n五、分支 # 列出所有本地分支\n$ git branch\n# 列出所有远程分支\n$ git branch -r\n# 列出所有本地分支和远程分支\n$ git branch -a\n# 新建一个分支，但依然停留在当前分支\n$ git branch [branch-name]\n# 新建一个分支，并切换到该分支\n$ git checkout -b [branch]\n# 新建一个分支，指向指定commit\n$ git branch [branch] [commit]\n# 新建一个分支，与指定的远程分支建立追踪关系\n$ git branch \u0026ndash;track [branch] [remote-branch]\n# 切换到指定分支，并更新工作区\n$ git checkout [branch-name]\n# 切换到上一个分支\n$ git checkout -\n# 建立追踪关系，在现有分支与指定的远程分支之间\n$ git branch \u0026ndash;set-upstream [branch] [remote-branch]\n# 合并指定分支到当前分支\n$ git merge [branch]\n# 选择一个commit，合并进当前分支\n$ git cherry-pick [commit]\n# 删除分支\n$ git branch -d [branch-name]\n# 删除远程分支\n$ git push origin \u0026ndash;delete [branch-name]\n$ git branch -dr [remote/branch]\n六、标签 # 列出所有tag\n$ git tag\n# 新建一个tag在当前commit\n$ git tag [tag]\n# 新建一个tag在指定commit\n$ git tag [tag] [commit]\n# 删除本地tag\n$ git tag -d [tag]\n# 删除远程tag\n$ git push origin :refs/tags/[tagName]\n# 查看tag信息\n$ git show [tag]\n# 提交指定tag\n$ git push [remote] [tag]\n# 提交所有tag\n$ git push [remote] \u0026ndash;tags\n# 新建一个分支，指向某个tag\n$ git checkout -b [branch] [tag]\n七、查看信息 # 显示有变更的文件\n$ git status\n# 显示当前分支的版本历史\n$ git log\n# 显示commit历史，以及每次commit发生变更的文件\n$ git log \u0026ndash;stat\n# 搜索提交历史，根据关键词\n$ git log -S [keyword]\n# 显示某个commit之后的所有变动，每个commit占据一行\n$ git log [tag] HEAD \u0026ndash;pretty=format:%s\n# 显示某个commit之后的所有变动，其\u0026quot;提交说明\u0026quot;必须符合搜索条件\n$ git log [tag] HEAD \u0026ndash;grep feature\n# 显示某个文件的版本历史，包括文件改名\n$ git log \u0026ndash;follow [file]\n$ git whatchanged [file]\n# 显示指定文件相关的每一次diff\n$ git log -p [file]\n# 显示过去5次提交\n$ git log -5 \u0026ndash;pretty \u0026ndash;oneline\n# 显示所有提交过的用户，按提交次数排序\n$ git shortlog -sn\n# 显示指定文件是什么人在什么时间修改过\n$ git blame [file]\n# 显示暂存区和工作区的代码差异\n$ git diff\n# 显示暂存区和上一个commit的差异\n$ git diff \u0026ndash;cached [file]\n# 显示工作区与当前分支最新commit之间的差异\n$ git diff HEAD\n# 显示两次提交之间的差异\n$ git diff [first-branch]\u0026hellip;[second-branch]\n# 显示今天你写了多少行代码\n$ git diff \u0026ndash;shortstat \u0026ldquo;@{0 day ago}\u0026rdquo;\n# 显示某次提交的元数据和内容变化\n$ git show [commit]\n# 显示某次提交发生变化的文件\n$ git show \u0026ndash;name-only [commit]\n# 显示某次提交时，某个文件的内容\n$ git show [commit]:[filename]\n# 显示当前分支的最近几次提交\n$ git reflog\n# 从本地master拉取代码更新当前分支：branch 一般为master\n$ git rebase [branch]\n八、远程同步 $ git remote update \u0026ndash;更新远程仓储\n# 下载远程仓库的所有变动\n$ git fetch [remote]\n# 显示所有远程仓库\n$ git remote -v\n# 显示某个远程仓库的信息\n$ git remote show [remote]\n# 增加一个新的远程仓库，并命名\n$ git remote add [shortname] [url]\n# 取回远程仓库的变化，并与本地分支合并\n$ git pull [remote] [branch]\n# 上传本地指定分支到远程仓库\n$ git push [remote] [branch]\n# 强行推送当前分支到远程仓库，即使有冲突\n$ git push [remote] \u0026ndash;force\n# 推送所有分支到远程仓库\n$ git push [remote] \u0026ndash;all\n九、撤销 # 恢复暂存区的指定文件到工作区\n$ git checkout [file]\n# 恢复某个commit的指定文件到暂存区和工作区\n$ git checkout [commit] [file]\n# 恢复暂存区的所有文件到工作区\n$ git checkout .\n# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变\n$ git reset [file]\n# 重置暂存区与工作区，与上一次commit保持一致\n$ git reset \u0026ndash;hard\n# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变\n$ git reset [commit]\n# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致\n$ git reset \u0026ndash;hard [commit]\n# 重置当前HEAD为指定commit，但保持暂存区和工作区不变\n$ git reset \u0026ndash;keep [commit]\n# 新建一个commit，用来撤销指定commit\n# 后者的所有变化都将被前者抵消，并且应用到当前分支\n$ git revert [commit]\n# 暂时将未提交的变化移除，稍后再移入\n$ git stash\n$ git stash pop\n十、其他 # 生成一个可供发布的压缩包\n$ git archive\n","date":"2019-02-18T00:00:00Z","permalink":"http://localhost:1313/p/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Git常用命令"},{"content":"1. Nginx 常用操作整理 1.1 启动 Nginx 1 ./sbin/nginx 1.2 停止 Nginx 1 2 3 ./sbin/nginx -s stop ./sbin/nginx -s quit -s 都是采用向 Nginx 发送信号的方式。 1.3 重载 Nginx 1 ./sbin/nginx -s reload 1.4 指定配置文件 1 ./sbin/nginx -c /etc/nginx/nginx.conf 1.5 配置语法检查 1 2 3 ./sbin/nginx -t /etc/nginx/nginx.conf 常规用法： ./sbin/nginx -tc /etc/nginx/nginx.conf 2. 配置文件详解 Nginx配置文件的分块下，基本就分为以下几块：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 main # 全局设置 events { # Nginx工作模式 .... } http { # http设置 .... upstream myproject { # 负载均衡服务器设置 ..... } server { # 主机设置 .... location { # URL匹配 .... } } server { .... location { .... } } .... } 2.1 main模块 下面是一个main区域，它是一个全局的设置：\n1 2 3 4 5 user nobody nobody; worker_processes 2; error_log /usr/local/var/log/nginx/error.log notice; pid /usr/local/var/run/nginx/nginx.pid; worker_rlimit_nofile 1024; user 来指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行。\nworker_processes 来指定了Nginx要开启的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验，一般指定1个进程就足够了，如果是多核CPU，建议指定和CPU的数量一样的进程数即可。我这里写2，那么就会开启2个子进程，总共3个进程。\nerror_log 来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。\npid 来指定进程id的存储文件位置。\nworker_rlimit_nofile 来指定一个nginx进程可以打开的最多文件描述符数目，这里是65535，需要使用命令“ulimit -n 65535”来设置。\n2.2 events模块 events模块来用指定nginx的工作模式和工作模式及连接数上限，一般是这样：\n1 2 3 4 events { use kqueue; #mac平台 worker_connections 1024; } use 用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在BSD系统中，因为Mac基于BSD,所以Mac也得用这个模式，对于Linux系统，epoll工作模式是首选。\nworker_connections 用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定，即Max_clients = worker_processes * worker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes * worker_connections / 4。\n进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。\n2.3 http模块 http模块可以说是最核心的模块了，它负责HTTP服务器相关属性的配置，它里面的server和upstream子模块，至关重要，等到反向代理和负载均衡以及虚拟目录等会仔细说。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 http { include mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /usr/local/var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 10; #gzip on; upstream myproject { ..... } server { .... } } 2.3.1 include 用来设定文件的mime类型,类型在配置文件目录下的mime.type文件定义，来告诉nginx来识别文件类型。\n2.3.2 default_type 设定了默认的类型为二进制流，也就是当文件类型未定义时使用这种方式，例如在没有配置asp的locate 环境时，Nginx是不予解析的，此时，用浏览器访问asp文件就会出现下载窗口了。\n2.3.3 log_format 用于设置日志的格式，和记录哪些参数，这里设置为main，刚好用于access_log来纪录这种类型。\n2.3.4 access_log 用来纪录每次的访问日志的文件地址，后面的main是日志的格式样式，对应于log_format的main。\n2.3.5 sendfile 用于开启高效文件传输模式。将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞。\n2.3.6 keepalive_timeout 设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接。\n6.4 server模块 server模块是http的子模块，它用来定一个虚拟主机，我们先讲最基本的配置，这些在后面再讲。我们看一下一个简单的server是如何做的？\n1 2 3 4 5 6 7 8 9 10 11 server { listen 8080; server_name localhost 192.168.12.10 www.yangyi.com; # 全局定义，如果都是这一个目录，这样定义最简单。 root /Users/yangyi/www; index index.php index.html index.htm; charset utf-8; access_log usr/local/var/log/host.access.log main; error_log usr/local/var/log/host.error.log error; .... } server 标志定义虚拟主机开始。\nlisten 用于指定虚拟主机的服务端口。\nserver_name 用来指定IP地址或者域名，多个域名之间用空格分开。\nroot 表示在这整个server虚拟主机内，全部的root web根目录。注意要和locate {}下面定义的区分开来。\nindex 全局定义访问的默认首页地址。注意要和locate {}下面定义的区分开来。\ncharset 用于设置网页的默认编码格式。\naccess_log 用来指定此虚拟主机的访问日志存放路径，最后的main用于指定访问日志的输出格式。\n2.5 location模块 location模块是nginx中用的最多的，也是最重要的模块了，什么负载均衡啊、反向代理啊、虚拟域名啊都与它相关。\nlocation根据它字面意思就知道是来定位的，定位URL，解析URL，所以，它也提供了强大的正则匹配功能，也支持条件判断匹配，用户可以通过location指令实现Nginx对动、静态网页进行过滤处理。像我们的php环境搭建就是用到了它。\n2.5.1 我们先来看这个，设定默认首页和虚拟机目录 1 2 3 4 location / { root /Users/yangyi/www; index index.php index.html index.htm; } location / 表示匹配访问根目录。\nroot 指令用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。\nindex 用于设定我们只输入域名后访问的默认首页地址，有个先后顺序：index.php index.html index.htm，如果没有开启目录浏览权限，又找不到这些默认首页，就会报403错误。\n2.5.2 location 还有一种方式就是正则匹配 下面这个例子是运用正则匹配来链接php。我们之前搭建环境也是这样做：\n1 2 3 4 5 6 location ~ \\.php$ { root /Users/yangyi/www; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } .php$ 熟悉正则的我们直到，这是匹配.php结尾的URL，用来解析php文件。里面的root也是一样，用来表示虚拟主机的根目录。 fastcgi_pass 链接的是php-fpm的地址。其他几个参数我们以后再说。\nlocation 还有其他用法，等讲到实例的时候，再看吧。\n2.6 upstream模块 upstream 模块负责负载均衡模块，通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。先学习怎么用，具体的使用实例以后再说。\n1 2 3 4 5 6 7 upstream deveye.cn{ ip_hash; server 192.168.12.1:80; server 192.168.12.2:80 down; server 192.168.12.3:8080 max_fails=3 fail_timeout=20s; server 192.168.12.4:8080; } 在上面的例子中，通过upstream指令指定了一个负载均衡器的名称iyangyi.com。这个名称可以任意指定，在后面需要的地方直接调用即可。里面是ip_hash这是其中的一种负载均衡调度算法，下面会着重介绍。紧接着就是各种服务器了。用server关键字表识，后面接ip。\nNginx的负载均衡模块目前支持4种调度算法：\nweight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight，指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。\nip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。\nfair（第三方）。比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。\nurl_hash（第三方）。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx的hash软件包。\n在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有：\ndown，表示当前的server暂时不参与负载均衡。\nbackup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。\nmax_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。\nfail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。\n注意：当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。\n转载自 ：https://www.jianshu.com/p/f04733896a48\n","date":"2019-01-18T00:00:00Z","permalink":"http://localhost:1313/p/nginx%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/","title":"Nginx基本配置"},{"content":"Replication Redis使用主从复制非常简单，它允许从实例成为主实例的副本，每当链接断开时，从节点将自动重新连接到主服务器上。并且无论主服务器发生什么情况，从节点都尝试完全复制所有数据。\nRedis主从复制使用以下三种机制： 当主从实例连接良好时，主节点向从节点发送命令流来进行更新，是为了复制由于Key过期或回收等其他操作对数据产生影响。 当主从实例断开时，从节点重新连接后只会尝试获取链接断开期间错开的命令流。 如果无法进行部分重新同步，则会要求完全重新同步。 默认情况下，Redis会使用异步复制，Redis从节点会异步地确认接收的数据。因此，主节点不会等待从节点处理完成。但是，如果需要知道从节点都处理了那些命令，也可以选择同步复制。\nRedis 复制的几个特征： Redis是使用异步复制 一个主节点可以有多个从节点 从节点还可以有子节点，从Redis 4.0开始，所有子节点将从主节点接收完全相同的复制流。 Redis主从复制是无阻塞的，意味着在进行复制或同步是仍然可以进行数据查询 复制既可以用于可伸缩性，也可以用于只读查询的多个副本（读写分离） 可以配置主节点不进行数据保存或只启用AOF，然后将数据保存到副本，但是注意:当服务器重启后，从节点服务器重新同步数据时，同时会清空从节点数据。 Redis 复制的原理： 每个Redis Master 节点都有一个replication ID:这是一个较大的伪随机字符串，用于标记当前数据集。每个Master 还有一个偏移量，该偏移量会针对复制流中要发送到副本的每个字节的增量而增加。 以便更新副本的状态。即使未连接任何副本，复制偏移也会增加。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Replication role:master connected_slaves:1 slave0:ip=39.105.157.176,port=6379,state=online,offset=61238,lag=0 # 主 Replication ID master_replid:649255ffb2183786d00203aa51715169b06f4f47 # 副 Replication ID master_replid2:0000000000000000000000000000000000000000 master_repl_offset:61238 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:61238 当从节点连接主节点时，会使用PSYNC命令来发送当前旧的主节点的Replication ID和offset，这样主节点只会同步相差的数据量，如果主节点缓冲区的副本引用（Replication ID）不存在，则会进行全量同步。\n全量同步的工作流程如下： 主节点开始后台生成RDB文件。同时，它开始缓冲从客户端收到的所有新写入命令。后台保存完成后，主数据库将数据库文件传输到从节点，从节点将其保存在磁盘上，然后将其加载到内存中。然后，主服务器将所有缓冲的命令发送到副本。\nReplication ID 说明： 如果两个实例具有相同的Replication ID和offset，则它们具有完全相同的数据。但是为什么会有两个Replication ID(主和副)？\n因为两个实例A和B具有相同的Replication ID，但一个实例的offset为1000，另一个实例的offset为1023，则意味着第一个实例缺少应用于数据集的某些命令。这也意味着，仅通过应用一些命令，A即可达到与B完全相同的状态。\nRedis实例具有两个Replication ID的原因是由于副本被提升为主副本。故障转移后，升级后的副本仍需要记住其过去的Replication ID，因为该Replication ID是以前的主副本之一。这样，当其他副本将与新的主副本同步时，它们将尝试使用旧的主Replication ID执行部分重新同步。因为将副本提升为主副本时，它会将其辅助ID设置为其主ID，并记住发生此ID切换时的offset。稍后它将选择一个新的随机Replication ID，因为新的历史记录开始了。处理新的副本连接时，主机将其ID和offset与当前ID和辅助ID相匹配（为安全起见，直到给定的偏移量）。简而言之，这意味着在故障转移后，连接到新提升的主服务器的副本不必执行完全同步。\n无盘复制 通常，完全重新同步需要在磁盘上创建RDB文件，然后从磁盘重新加载相同的RDB，以便为副本提供数据。 但是对于硬盘速度慢，但是在内网环境下，可以采用无盘复制，这样可以直接通过Socket将RDB发送给从节点，而无需使用硬盘作为中间存储。\n配置 1 replicaof 192.168.1.1 6379 也可以使用REPLICAOF命令进行同步。 可以使用repl-diskless-sync配置参数启用无盘复制。在repl-diskless-sync-delay 参数控制第一个副本之后，为了等待更多副本到达而开始传输的延迟。\n1 masterauth \u0026lt;password\u0026gt; 设置主节点的密码，也可以使用redis-cli输入config set masterauth \u0026lt;password\u0026gt;进行设置。\n1 2 3 4 # 在当前至少有N个副本连接到主服务器时才接受写查询 min-replicas-to-write \u0026lt;number of replicas\u0026gt; # 在有N个副本延迟少于M秒时，则接受写入 min-replicas-max-lag \u0026lt;number of seconds\u0026gt; ","date":"2018-07-07T00:00:00Z","permalink":"http://localhost:1313/p/redis%E5%A4%8D%E5%88%B6/","title":"Redis复制"},{"content":"下载 从Redis官网下载redis 最新稳定版本 解压到 /usr/local/ 目录下 安装 1 make \u0026amp;\u0026amp; make test \u0026amp;\u0026amp; make install make时报如下错误:\n1 2 3 4 5 zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory zmalloc.h:55:2: error: #error \u0026#34;Newer version of jemalloc required\u0026#34; make[1]: *** [adlist.o] Error 1 make[1]: Leaving directory `/data0/src/redis-2.6.2/src\u0026#39; make: *** [all] Error 2 原因是jemalloc重载了Linux下的ANSI C的malloc和free函数。 解决办法：\n1 make MALLOC=libc redis 生产环境启动方案 redis utils 目录下，有个redis_init_script脚本 将redis_init_script脚本拷贝到linux的/etc/init.d 目录中，将redis_init_script重命名为redis_6379, 6379是我们希望redis 的实例端口号 创建两个目录 /etc/redis (存放redis 配置的目录), /var/redis/6379 (存放redis的持久文件) 修改redis.conf配置文件（默认在根目录下），拷贝到/etc/redis目录下，修改名称为6379.conf 修改redis.conf中的部分配置为生产环境 参数 值 说明 daemonize yes 让redis以daemon进程运行 pidfile /var/run/redis_6379.pid 设置redis的pid文件位置 port 6379 设置redis的监听端口号 dir /var/redis/6379 设置持久化文件的存储位置 启动redis: 1 2 3 cd /etc/init.d chmod 777 redis_6379 ./redis_6379 start 确认redis 进程是否启动: ps -ef | grep redis 让redis跟随系统启动自动启动，在redis_6379 脚本中，最上面加入两行注释 1 2 3 # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database chkconfig redis_6379 on 主从架构（主节点和从节点最好保证一致的版本） 在 slave node 上配置: 1 slaveof 192.168.1.1 6379 强制读写分离 基于主从复制架构，实现读写分离 redis slave node 只读，默认开启，slave-read-only 开启了只读的redis slave node，会拒绝所有的写操作，这样可以强制搭建成读写分离架构\n集成安全认证 master 上启用安全认证策略，requirepass master 连接口令 masterauth\n读写分离架构的测试 先启动主节点，再启动从节点，在搭建生产环境的时候，不要忘记修改一个配置：\n1 bind 127.0.0.1 每个redis.conf 中的bind 127.0.0.1 -\u0026gt; bind自己的ip，并且防火墙打开6379端口\nredis-cli的使用 命令 说明 redis-cli shutdown 连接本机的6379端口停止redis进程 redis-cli -h 127.0.0.1 -p 6379 指定要连接的ip和端口号 redis-cli ping ping redis的端口，看是否正常 redis-cli 进入交互式命令行 set k1 v1 设置一个key:value get k1 获取key的值 ","date":"2018-07-06T00:00:00Z","permalink":"http://localhost:1313/p/redis%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","title":"Redis安装与配置"},{"content":"Redis的持久化机制-RDB 1.什么是RDB The RDB persistence performs point-in-time snapshots of your dataset at specified intervals.(RDB持久化是以指定的时间间隔执行数据集的时间点快照。) 简单来说，RDB是每隔一段时间，会把内存中的数据写入磁盘的临时文件作为快照，恢复时把快照文件读取到内存中。如果机器宕机，那么内存中的数据就会丢失，使用RDB机制后，重启后数据会恢复。\n2.备份与恢复 内存备份 \u0026ndash;\u0026gt; 磁盘临时文件 临时文件 \u0026ndash;\u0026gt; 恢复到内存\n3.RDB优劣势 优势\n每隔一段时间全量备份 容灾简单，适合进行远程冷备份 子进程备份的时候，主进程不会有任何IO操作（不会有写入或修改），保证备份数据的完整性 相对AOF来说，当有更大的文件时候可以快速重启恢复 劣势\n发生故障时，可能会丢失最后一次备份数据 子进程所占用的内存会和父进程一模一样，会造成CPU负担 由于定时全量备份是重量级操作，所以对于实时备份，就无法处理了 4.RDB的配置 保存位置可以自定义配置: 1 dir /var/redis/6379/dump.rdb 保存机制 1 2 3 4 5 6 7 8 # save \u0026lt;seconds\u0026gt; \u0026lt;changes\u0026gt; # 900秒（15分钟）后，如果至少有 1 个Key发生改变 # 300秒（5分钟）后，如果至少有 10 个Key发生改变 # 60秒（1分钟）后，如果至少有 10000 个Key发生改变 save 900 1 save 300 10 save 60 10000 Redis的持久化机制-AOF 1.什么是AOF The AOF persistence logs every write operation received by the server, that will be played again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Redis protocol itself, in an append-only fashion. Redis is able to rewrite the log in the background when it gets too big.\nAOF持久化会记录服务器接收到的每个写入操作，这些操作将在服务器启动时再次执行，以重新构建原始的数据。命令记录的格式与Redis协议本身的格式相同，采用追加方式。当日志文件过大时，Redis可以在后台进行rewrite。\n2.备份与恢复 日志备份 \u0026ndash;\u0026gt; 命令追加方式 日志文件 \u0026ndash;\u0026gt; 根据命令日志文件重新构建\n3.AOF优劣势 优势 使用AOF数据持久化更加完整 可以使用不同的fsync策略，使用默认策略fsync时，每秒的写入性能仍然很好（fsync是使用后台线程执行的，并且在没有进行fsync的情况下，主线程将尽力执行写入操作）但是会损失一秒的写入时间 AOF是使用日志追加的方式，如果断电或其他原因导致日志只写了一半，可以使用redis-check-aof工具进行修复 Redis太大时，Redis可以在后台自动重写AOF。 Redis继续追加到旧文件时，会生成一个新的文件，其中包含创建当前数据集所需的最少操作集，一旦准备好第二个文件，Redis会切换这两个文件并开始追加到新的那一个 即使使用FLUSHALL命令清空了所有数据，也可以通过修改AOF文件进行数据恢复 劣势 AOF相比RDB占用空间更大 使用fsync策略后，相比RDB性能差一些 当服务器宕机后，使用AOF恢复的数据可能不完整 4.AOF的配置 开启AOF 1 appendonly yes 配置fsync策略 1 2 3 4 5 6 # If unsure, use \u0026#34;everysec\u0026#34;. # 如果不确定，推荐使用 \u0026#34;everysec\u0026#34; # appendfsync always appendfsync everysec # appendfsync no AOF rewrite配置 1 2 3 4 # 设置一个百分比 auto-aof-rewrite-percentage 100 # 设置AOF 的最小大小 auto-aof-rewrite-min-size 64mb Redis 启动加载配置 1 2 # 优先加载AOF 文件 aof-use-rdb-preamble yes 两种持久化方式改如何选择 如果对数据可靠性要求很高，则应同时使用两种持久性方式。 如果在灾难情况下仍然可以承受几分钟的数据丢失，则可以仅使用RDB。 不推荐单独使用AOF，因为AOF在数据恢复时，有时候会出现Bugs。 ","date":"2018-07-06T00:00:00Z","permalink":"http://localhost:1313/p/redis%E6%8C%81%E4%B9%85%E5%8C%96/","title":"Redis持久化"},{"content":"三个有启发的学习方法 看似最笨的学习方法\u0026mdash;-笔记和记忆力\u0026mdash;-偏偏造就了最高的开发效率。\n如果没有对旧事物进行大量练习，你不太可能发现新事物\n要想多学，就必须能在学习中得到快乐。做到这一点的唯一方法，就是努力学习你最感兴趣的东西。\nhttps://www.ruanyifeng.com/blog/2022/04/weekly-issue-202.html\n","date":"2018-06-06T00:00:00Z","permalink":"http://localhost:1313/p/%E9%9A%8F%E6%89%8B%E8%AE%B0/","title":"随手记"}]